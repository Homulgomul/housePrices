{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-26 23:52:00.352376: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-26 23:52:00.373292: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-03-26 23:52:00.373314: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-03-26 23:52:00.373852: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-03-26 23:52:00.377440: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import tensorflow as tf\n",
    "\n",
    "from scripts.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-26 23:52:01.261761: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-26 23:52:01.265021: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-26 23:52:01.265053: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n"
     ]
    }
   ],
   "source": [
    "#use gpu for tf\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "train_data = pd.read_csv('../data/train.csv')\n",
    "test_data = pd.read_csv('../data/test.csv')\n",
    "\n",
    "# split train data into predictors and response\n",
    "X = train_data.drop(columns=['SalePrice'])\n",
    "y = train_data['SalePrice'] \n",
    "\n",
    "#combine the data for preprocessing\n",
    "data = pd.concat([X, test_data], axis=0)\n",
    "# Preprocess the data\n",
    "data = Pipeline(data)\n",
    "\n",
    "# Split the data back into train and test, processed\n",
    "X = data[:len(train_data)]\n",
    "test = data[len(train_data):]\n",
    "#increase test index by 1\n",
    "test.index = test.index + 1\n",
    "\n",
    "# Split the data into features and response\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearRegression MSE: 5.401053165269924e+34\n",
      "LinearRegression R^2: -7.041490830219341e+24\n",
      "RandomForestRegressor MSE: 848303943.3586905\n",
      "RandomForestRegressor R^2: 0.8894044502874172\n",
      "SVR MSE: 7858659144.939162\n",
      "SVR R^2: -0.024553445663832107\n",
      "GradientBoostingRegressor MSE: 742905824.9417056\n",
      "GradientBoostingRegressor R^2: 0.9031454719297858\n",
      "AdaBoostRegressor MSE: 1276963960.9349034\n",
      "AdaBoostRegressor R^2: 0.8335189499843718\n",
      "BaggingRegressor MSE: 1026556179.3085959\n",
      "BaggingRegressor R^2: 0.8661652514404525\n",
      "ExtraTreesRegressor MSE: 829888658.9413068\n",
      "ExtraTreesRegressor R^2: 0.8918052979071871\n",
      "HistGradientBoostingRegressor MSE: 857279866.6666343\n",
      "HistGradientBoostingRegressor R^2: 0.8882342362618998\n"
     ]
    }
   ],
   "source": [
    "# try a few models\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "\n",
    "models = [\n",
    "    LinearRegression(),\n",
    "    RandomForestRegressor(),\n",
    "    SVR(),\n",
    "    GradientBoostingRegressor(),\n",
    "    AdaBoostRegressor(),\n",
    "    BaggingRegressor(),\n",
    "    ExtraTreesRegressor(),\n",
    "    HistGradientBoostingRegressor(),\n",
    "]\n",
    "\n",
    "for model in models:\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    print(f'{model.__class__.__name__} MSE: {mean_squared_error(y_test, y_pred)}')\n",
    "    print(f'{model.__class__.__name__} R^2: {model.score(X_test, y_test)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-26 23:52:05.761095: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-26 23:52:05.761145: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-26 23:52:05.761165: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-26 23:52:05.843845: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-26 23:52:05.843887: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-26 23:52:05.843892: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2022] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2024-03-26 23:52:05.843918: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-26 23:52:05.843932: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21784 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "# build nn model\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Dense(128, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-26 23:52:06.407202: I external/local_xla/xla/service/service.cc:168] XLA service 0x7f3f71f6fa00 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-03-26 23:52:06.407225: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 3090, Compute Capability 8.6\n",
      "2024-03-26 23:52:06.410273: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-03-26 23:52:06.419395: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8906\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1711497126.457762   94867 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37/37 [==============================] - 1s 4ms/step - loss: 38885306368.0000 - val_loss: 39653486592.0000\n",
      "Epoch 2/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 38884700160.0000 - val_loss: 39652683776.0000\n",
      "Epoch 3/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 38883627008.0000 - val_loss: 39651209216.0000\n",
      "Epoch 4/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 38881746944.0000 - val_loss: 39648759808.0000\n",
      "Epoch 5/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 38878765056.0000 - val_loss: 39644934144.0000\n",
      "Epoch 6/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 38874427392.0000 - val_loss: 39639625728.0000\n",
      "Epoch 7/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 38868414464.0000 - val_loss: 39632621568.0000\n",
      "Epoch 8/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 38860509184.0000 - val_loss: 39623311360.0000\n",
      "Epoch 9/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 38850367488.0000 - val_loss: 39611404288.0000\n",
      "Epoch 10/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 38837084160.0000 - val_loss: 39596294144.0000\n",
      "Epoch 11/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 38819528704.0000 - val_loss: 39575146496.0000\n",
      "Epoch 12/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 38796095488.0000 - val_loss: 39548960768.0000\n",
      "Epoch 13/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 38767460352.0000 - val_loss: 39517065216.0000\n",
      "Epoch 14/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 38733033472.0000 - val_loss: 39479631872.0000\n",
      "Epoch 15/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 38693302272.0000 - val_loss: 39434862592.0000\n",
      "Epoch 16/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 38647087104.0000 - val_loss: 39384571904.0000\n",
      "Epoch 17/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 38594396160.0000 - val_loss: 39327526912.0000\n",
      "Epoch 18/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 38534971392.0000 - val_loss: 39263649792.0000\n",
      "Epoch 19/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 38467989504.0000 - val_loss: 39193542656.0000\n",
      "Epoch 20/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 38394392576.0000 - val_loss: 39114072064.0000\n",
      "Epoch 21/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 38312448000.0000 - val_loss: 39029600256.0000\n",
      "Epoch 22/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 38225182720.0000 - val_loss: 38933200896.0000\n",
      "Epoch 23/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 38128259072.0000 - val_loss: 38831718400.0000\n",
      "Epoch 24/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 38023548928.0000 - val_loss: 38723350528.0000\n",
      "Epoch 25/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 37911482368.0000 - val_loss: 38602924032.0000\n",
      "Epoch 26/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 37790748672.0000 - val_loss: 38476574720.0000\n",
      "Epoch 27/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 37661618176.0000 - val_loss: 38342762496.0000\n",
      "Epoch 28/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 37523415040.0000 - val_loss: 38202302464.0000\n",
      "Epoch 29/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 37376950272.0000 - val_loss: 38048202752.0000\n",
      "Epoch 30/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 37220872192.0000 - val_loss: 37885988864.0000\n",
      "Epoch 31/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 37057155072.0000 - val_loss: 37713223680.0000\n",
      "Epoch 32/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 36883341312.0000 - val_loss: 37533999104.0000\n",
      "Epoch 33/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 36700282880.0000 - val_loss: 37348122624.0000\n",
      "Epoch 34/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 36510613504.0000 - val_loss: 37143379968.0000\n",
      "Epoch 35/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 36308758528.0000 - val_loss: 36936822784.0000\n",
      "Epoch 36/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 36100272128.0000 - val_loss: 36725186560.0000\n",
      "Epoch 37/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 35883712512.0000 - val_loss: 36500299776.0000\n",
      "Epoch 38/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 35658248192.0000 - val_loss: 36268527616.0000\n",
      "Epoch 39/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 35425742848.0000 - val_loss: 36024963072.0000\n",
      "Epoch 40/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 35179835392.0000 - val_loss: 35775258624.0000\n",
      "Epoch 41/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 34927833088.0000 - val_loss: 35509882880.0000\n",
      "Epoch 42/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 34667130880.0000 - val_loss: 35244838912.0000\n",
      "Epoch 43/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 34399207424.0000 - val_loss: 34970349568.0000\n",
      "Epoch 44/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 34123776000.0000 - val_loss: 34681843712.0000\n",
      "Epoch 45/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 33837715456.0000 - val_loss: 34389745664.0000\n",
      "Epoch 46/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 33542234112.0000 - val_loss: 34088951808.0000\n",
      "Epoch 47/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 33242050560.0000 - val_loss: 33781925888.0000\n",
      "Epoch 48/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 32934232064.0000 - val_loss: 33463676928.0000\n",
      "Epoch 49/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 32618020864.0000 - val_loss: 33139167232.0000\n",
      "Epoch 50/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 32293580800.0000 - val_loss: 32812673024.0000\n",
      "Epoch 51/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 31961870336.0000 - val_loss: 32474126336.0000\n",
      "Epoch 52/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 31623368704.0000 - val_loss: 32127535104.0000\n",
      "Epoch 53/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 31278508032.0000 - val_loss: 31774431232.0000\n",
      "Epoch 54/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 30926315520.0000 - val_loss: 31411214336.0000\n",
      "Epoch 55/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 30568079360.0000 - val_loss: 31043368960.0000\n",
      "Epoch 56/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 30204246016.0000 - val_loss: 30673246208.0000\n",
      "Epoch 57/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 29835110400.0000 - val_loss: 30297241600.0000\n",
      "Epoch 58/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 29458808832.0000 - val_loss: 29912479744.0000\n",
      "Epoch 59/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 29077438464.0000 - val_loss: 29525970944.0000\n",
      "Epoch 60/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 28694753280.0000 - val_loss: 29129920512.0000\n",
      "Epoch 61/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 28302761984.0000 - val_loss: 28737167360.0000\n",
      "Epoch 62/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 27910942720.0000 - val_loss: 28333187072.0000\n",
      "Epoch 63/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 27511040000.0000 - val_loss: 27933612032.0000\n",
      "Epoch 64/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 27116292096.0000 - val_loss: 27519211520.0000\n",
      "Epoch 65/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 26710994944.0000 - val_loss: 27113457664.0000\n",
      "Epoch 66/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 26307446784.0000 - val_loss: 26692898816.0000\n",
      "Epoch 67/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 25894225920.0000 - val_loss: 26279817216.0000\n",
      "Epoch 68/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 25483341824.0000 - val_loss: 25859762176.0000\n",
      "Epoch 69/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 25070112768.0000 - val_loss: 25441540096.0000\n",
      "Epoch 70/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 24654708736.0000 - val_loss: 25015957504.0000\n",
      "Epoch 71/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 24237133824.0000 - val_loss: 24590366720.0000\n",
      "Epoch 72/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 23817512960.0000 - val_loss: 24168650752.0000\n",
      "Epoch 73/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 23400724480.0000 - val_loss: 23741683712.0000\n",
      "Epoch 74/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 22978603008.0000 - val_loss: 23318822912.0000\n",
      "Epoch 75/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 22561812480.0000 - val_loss: 22884651008.0000\n",
      "Epoch 76/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 22138335232.0000 - val_loss: 22465724416.0000\n",
      "Epoch 77/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 21721159680.0000 - val_loss: 22034276352.0000\n",
      "Epoch 78/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 21301348352.0000 - val_loss: 21608542208.0000\n",
      "Epoch 79/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 20882235392.0000 - val_loss: 21197404160.0000\n",
      "Epoch 80/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 20470558720.0000 - val_loss: 20764155904.0000\n",
      "Epoch 81/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 20054587392.0000 - val_loss: 20344592384.0000\n",
      "Epoch 82/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 19641075712.0000 - val_loss: 19924963328.0000\n",
      "Epoch 83/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 19230435328.0000 - val_loss: 19505080320.0000\n",
      "Epoch 84/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 18825543680.0000 - val_loss: 19088918528.0000\n",
      "Epoch 85/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 18423218176.0000 - val_loss: 18682718208.0000\n",
      "Epoch 86/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 18023325696.0000 - val_loss: 18283069440.0000\n",
      "Epoch 87/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 17629601792.0000 - val_loss: 17875943424.0000\n",
      "Epoch 88/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 17236107264.0000 - val_loss: 17481975808.0000\n",
      "Epoch 89/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 16848919552.0000 - val_loss: 17082035200.0000\n",
      "Epoch 90/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 16464663552.0000 - val_loss: 16698190848.0000\n",
      "Epoch 91/1000\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 16090205184.0000 - val_loss: 16311150592.0000\n",
      "Epoch 92/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 15717036032.0000 - val_loss: 15935475712.0000\n",
      "Epoch 93/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 15348469760.0000 - val_loss: 15564453888.0000\n",
      "Epoch 94/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 14988093440.0000 - val_loss: 15195848704.0000\n",
      "Epoch 95/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 14630577152.0000 - val_loss: 14840010752.0000\n",
      "Epoch 96/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 14284726272.0000 - val_loss: 14478782464.0000\n",
      "Epoch 97/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 13940454400.0000 - val_loss: 14129908736.0000\n",
      "Epoch 98/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 13603107840.0000 - val_loss: 13789569024.0000\n",
      "Epoch 99/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 13273525248.0000 - val_loss: 13453260800.0000\n",
      "Epoch 100/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 12949842944.0000 - val_loss: 13124200448.0000\n",
      "Epoch 101/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 12633203712.0000 - val_loss: 12806956032.0000\n",
      "Epoch 102/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 12325694464.0000 - val_loss: 12485616640.0000\n",
      "Epoch 103/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 12021477376.0000 - val_loss: 12179101696.0000\n",
      "Epoch 104/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 11725789184.0000 - val_loss: 11886402560.0000\n",
      "Epoch 105/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 11436402688.0000 - val_loss: 11592636416.0000\n",
      "Epoch 106/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 11155991552.0000 - val_loss: 11298489344.0000\n",
      "Epoch 107/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 10879357952.0000 - val_loss: 11025212416.0000\n",
      "Epoch 108/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 10615634944.0000 - val_loss: 10755392512.0000\n",
      "Epoch 109/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 10357412864.0000 - val_loss: 10493646848.0000\n",
      "Epoch 110/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 10106630144.0000 - val_loss: 10239219712.0000\n",
      "Epoch 111/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 9863163904.0000 - val_loss: 9992348672.0000\n",
      "Epoch 112/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 9626824704.0000 - val_loss: 9750927360.0000\n",
      "Epoch 113/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 9398126592.0000 - val_loss: 9520125952.0000\n",
      "Epoch 114/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 9176927232.0000 - val_loss: 9294064640.0000\n",
      "Epoch 115/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 8961217536.0000 - val_loss: 9077376000.0000\n",
      "Epoch 116/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 8755855360.0000 - val_loss: 8865658880.0000\n",
      "Epoch 117/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 8555570176.0000 - val_loss: 8662675456.0000\n",
      "Epoch 118/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 8363590144.0000 - val_loss: 8467279872.0000\n",
      "Epoch 119/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 8177619968.0000 - val_loss: 8280399872.0000\n",
      "Epoch 120/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 7997131776.0000 - val_loss: 8100193280.0000\n",
      "Epoch 121/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 7823529472.0000 - val_loss: 7923531264.0000\n",
      "Epoch 122/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 7655168512.0000 - val_loss: 7756719616.0000\n",
      "Epoch 123/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 7493770240.0000 - val_loss: 7590772736.0000\n",
      "Epoch 124/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 7339136000.0000 - val_loss: 7431960576.0000\n",
      "Epoch 125/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 7188894720.0000 - val_loss: 7286411776.0000\n",
      "Epoch 126/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 7046723072.0000 - val_loss: 7138933760.0000\n",
      "Epoch 127/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 6907688960.0000 - val_loss: 7003429888.0000\n",
      "Epoch 128/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 6776142336.0000 - val_loss: 6869252096.0000\n",
      "Epoch 129/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 6648314368.0000 - val_loss: 6741801984.0000\n",
      "Epoch 130/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 6524673024.0000 - val_loss: 6619821056.0000\n",
      "Epoch 131/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 6406258688.0000 - val_loss: 6503428608.0000\n",
      "Epoch 132/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 6291739136.0000 - val_loss: 6390239232.0000\n",
      "Epoch 133/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 6181338624.0000 - val_loss: 6278273536.0000\n",
      "Epoch 134/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 6074103296.0000 - val_loss: 6174674432.0000\n",
      "Epoch 135/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 5971816960.0000 - val_loss: 6073367552.0000\n",
      "Epoch 136/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 5873653248.0000 - val_loss: 5971819008.0000\n",
      "Epoch 137/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 5777032192.0000 - val_loss: 5883357696.0000\n",
      "Epoch 138/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 5684241920.0000 - val_loss: 5789920768.0000\n",
      "Epoch 139/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 5593069568.0000 - val_loss: 5702448128.0000\n",
      "Epoch 140/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 5505934336.0000 - val_loss: 5618207232.0000\n",
      "Epoch 141/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 5420557824.0000 - val_loss: 5536409600.0000\n",
      "Epoch 142/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 5338352128.0000 - val_loss: 5457748992.0000\n",
      "Epoch 143/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 5258594816.0000 - val_loss: 5379293696.0000\n",
      "Epoch 144/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 5180783616.0000 - val_loss: 5306443264.0000\n",
      "Epoch 145/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 5103989248.0000 - val_loss: 5236836352.0000\n",
      "Epoch 146/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 5031268352.0000 - val_loss: 5162284544.0000\n",
      "Epoch 147/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 4957837824.0000 - val_loss: 5094992896.0000\n",
      "Epoch 148/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 4886952960.0000 - val_loss: 5028265984.0000\n",
      "Epoch 149/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 4817582592.0000 - val_loss: 4962973696.0000\n",
      "Epoch 150/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 4750349312.0000 - val_loss: 4899972096.0000\n",
      "Epoch 151/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 4684521472.0000 - val_loss: 4840250368.0000\n",
      "Epoch 152/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 4619975168.0000 - val_loss: 4778698752.0000\n",
      "Epoch 153/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 4556791808.0000 - val_loss: 4721444864.0000\n",
      "Epoch 154/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 4495323648.0000 - val_loss: 4665126912.0000\n",
      "Epoch 155/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 4434897408.0000 - val_loss: 4608462848.0000\n",
      "Epoch 156/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 4375619072.0000 - val_loss: 4554458112.0000\n",
      "Epoch 157/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 4317234688.0000 - val_loss: 4502419456.0000\n",
      "Epoch 158/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 4259737088.0000 - val_loss: 4448217088.0000\n",
      "Epoch 159/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 4204229120.0000 - val_loss: 4399604736.0000\n",
      "Epoch 160/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 4148659200.0000 - val_loss: 4348295168.0000\n",
      "Epoch 161/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 4094370048.0000 - val_loss: 4299096064.0000\n",
      "Epoch 162/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 4040620288.0000 - val_loss: 4252020480.0000\n",
      "Epoch 163/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 3988074240.0000 - val_loss: 4205507840.0000\n",
      "Epoch 164/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 3936757504.0000 - val_loss: 4158995456.0000\n",
      "Epoch 165/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 3885808896.0000 - val_loss: 4113442048.0000\n",
      "Epoch 166/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 3835986432.0000 - val_loss: 4071410176.0000\n",
      "Epoch 167/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 3787783680.0000 - val_loss: 4028936960.0000\n",
      "Epoch 168/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 3739001600.0000 - val_loss: 3986137088.0000\n",
      "Epoch 169/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 3692204800.0000 - val_loss: 3942449664.0000\n",
      "Epoch 170/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 3645412608.0000 - val_loss: 3900802304.0000\n",
      "Epoch 171/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 3600075520.0000 - val_loss: 3863152384.0000\n",
      "Epoch 172/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 3556067072.0000 - val_loss: 3823255296.0000\n",
      "Epoch 173/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 3512364032.0000 - val_loss: 3784804608.0000\n",
      "Epoch 174/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 3469279744.0000 - val_loss: 3748591616.0000\n",
      "Epoch 175/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 3427401984.0000 - val_loss: 3710186240.0000\n",
      "Epoch 176/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 3385993216.0000 - val_loss: 3672860160.0000\n",
      "Epoch 177/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 3345403648.0000 - val_loss: 3638169856.0000\n",
      "Epoch 178/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 3305667584.0000 - val_loss: 3603932160.0000\n",
      "Epoch 179/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 3266565632.0000 - val_loss: 3570514432.0000\n",
      "Epoch 180/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 3229439232.0000 - val_loss: 3537980160.0000\n",
      "Epoch 181/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 3190694912.0000 - val_loss: 3505051392.0000\n",
      "Epoch 182/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 3154512896.0000 - val_loss: 3470390528.0000\n",
      "Epoch 183/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 3117384960.0000 - val_loss: 3441740800.0000\n",
      "Epoch 184/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 3082257408.0000 - val_loss: 3412567296.0000\n",
      "Epoch 185/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 3047760384.0000 - val_loss: 3382100224.0000\n",
      "Epoch 186/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 3013758976.0000 - val_loss: 3351340544.0000\n",
      "Epoch 187/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 2980680192.0000 - val_loss: 3321695744.0000\n",
      "Epoch 188/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 2948090368.0000 - val_loss: 3295062272.0000\n",
      "Epoch 189/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 2916599296.0000 - val_loss: 3267190784.0000\n",
      "Epoch 190/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 2885252864.0000 - val_loss: 3241043712.0000\n",
      "Epoch 191/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 2854851840.0000 - val_loss: 3214856448.0000\n",
      "Epoch 192/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 2825004800.0000 - val_loss: 3190182400.0000\n",
      "Epoch 193/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 2796263424.0000 - val_loss: 3164268288.0000\n",
      "Epoch 194/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 2767791360.0000 - val_loss: 3140549632.0000\n",
      "Epoch 195/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 2740095744.0000 - val_loss: 3115057920.0000\n",
      "Epoch 196/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 2712549888.0000 - val_loss: 3093786624.0000\n",
      "Epoch 197/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 2686058496.0000 - val_loss: 3070144512.0000\n",
      "Epoch 198/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 2660204032.0000 - val_loss: 3048025600.0000\n",
      "Epoch 199/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 2635046144.0000 - val_loss: 3026836736.0000\n",
      "Epoch 200/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 2610491904.0000 - val_loss: 3006856192.0000\n",
      "Epoch 201/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 2586465536.0000 - val_loss: 2987057408.0000\n",
      "Epoch 202/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 2562420224.0000 - val_loss: 2968061952.0000\n",
      "Epoch 203/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 2540263680.0000 - val_loss: 2950388992.0000\n",
      "Epoch 204/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 2517206784.0000 - val_loss: 2930358528.0000\n",
      "Epoch 205/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 2495223808.0000 - val_loss: 2911796480.0000\n",
      "Epoch 206/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 2474018816.0000 - val_loss: 2894985728.0000\n",
      "Epoch 207/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 2452937472.0000 - val_loss: 2877877248.0000\n",
      "Epoch 208/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 2432825600.0000 - val_loss: 2861159936.0000\n",
      "Epoch 209/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 2412679680.0000 - val_loss: 2843662848.0000\n",
      "Epoch 210/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 2392833024.0000 - val_loss: 2828882944.0000\n",
      "Epoch 211/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 2373851392.0000 - val_loss: 2814596864.0000\n",
      "Epoch 212/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 2355131648.0000 - val_loss: 2798136064.0000\n",
      "Epoch 213/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 2337192960.0000 - val_loss: 2782312192.0000\n",
      "Epoch 214/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 2319635456.0000 - val_loss: 2770465792.0000\n",
      "Epoch 215/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 2301954560.0000 - val_loss: 2754838528.0000\n",
      "Epoch 216/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 2285332224.0000 - val_loss: 2741322752.0000\n",
      "Epoch 217/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 2268382208.0000 - val_loss: 2727891456.0000\n",
      "Epoch 218/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 2252096512.0000 - val_loss: 2715036416.0000\n",
      "Epoch 219/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 2236162048.0000 - val_loss: 2702439680.0000\n",
      "Epoch 220/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 2220890368.0000 - val_loss: 2690112768.0000\n",
      "Epoch 221/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 2206797824.0000 - val_loss: 2680020992.0000\n",
      "Epoch 222/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 2191382784.0000 - val_loss: 2667052544.0000\n",
      "Epoch 223/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 2176459008.0000 - val_loss: 2655316736.0000\n",
      "Epoch 224/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 2162018304.0000 - val_loss: 2643005184.0000\n",
      "Epoch 225/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 2147907328.0000 - val_loss: 2633660928.0000\n",
      "Epoch 226/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 2134486144.0000 - val_loss: 2623996928.0000\n",
      "Epoch 227/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 2120855808.0000 - val_loss: 2612572672.0000\n",
      "Epoch 228/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 2107323136.0000 - val_loss: 2600772864.0000\n",
      "Epoch 229/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 2094521344.0000 - val_loss: 2590686208.0000\n",
      "Epoch 230/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 2081743616.0000 - val_loss: 2581341440.0000\n",
      "Epoch 231/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 2069192832.0000 - val_loss: 2573086208.0000\n",
      "Epoch 232/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 2056561024.0000 - val_loss: 2564615680.0000\n",
      "Epoch 233/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 2044810112.0000 - val_loss: 2552747008.0000\n",
      "Epoch 234/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 2032615168.0000 - val_loss: 2545407744.0000\n",
      "Epoch 235/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 2020954112.0000 - val_loss: 2536435968.0000\n",
      "Epoch 236/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 2009215744.0000 - val_loss: 2528259840.0000\n",
      "Epoch 237/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 1997989248.0000 - val_loss: 2519407616.0000\n",
      "Epoch 238/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 1987228800.0000 - val_loss: 2513108992.0000\n",
      "Epoch 239/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 1976029824.0000 - val_loss: 2502596608.0000\n",
      "Epoch 240/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 1964982528.0000 - val_loss: 2495605248.0000\n",
      "Epoch 241/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 1954361216.0000 - val_loss: 2487539968.0000\n",
      "Epoch 242/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 1943911808.0000 - val_loss: 2481864448.0000\n",
      "Epoch 243/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 1933393024.0000 - val_loss: 2474529536.0000\n",
      "Epoch 244/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 1923670784.0000 - val_loss: 2465609472.0000\n",
      "Epoch 245/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 1913747072.0000 - val_loss: 2460760832.0000\n",
      "Epoch 246/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 1903013888.0000 - val_loss: 2452157440.0000\n",
      "Epoch 247/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 1893325568.0000 - val_loss: 2443370496.0000\n",
      "Epoch 248/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 1883633664.0000 - val_loss: 2434924800.0000\n",
      "Epoch 249/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 1874403584.0000 - val_loss: 2428509184.0000\n",
      "Epoch 250/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 1865093120.0000 - val_loss: 2423186688.0000\n",
      "Epoch 251/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 1855897728.0000 - val_loss: 2417900544.0000\n",
      "Epoch 252/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 1846200576.0000 - val_loss: 2410955776.0000\n",
      "Epoch 253/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 1837316736.0000 - val_loss: 2404058112.0000\n",
      "Epoch 254/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 1828326144.0000 - val_loss: 2398514944.0000\n",
      "Epoch 255/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 1819694848.0000 - val_loss: 2393719808.0000\n",
      "Epoch 256/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 1810578944.0000 - val_loss: 2386763520.0000\n",
      "Epoch 257/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 1802130048.0000 - val_loss: 2379716864.0000\n",
      "Epoch 258/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 1793828736.0000 - val_loss: 2373393664.0000\n",
      "Epoch 259/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 1784930560.0000 - val_loss: 2369500672.0000\n",
      "Epoch 260/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 1776767872.0000 - val_loss: 2364368128.0000\n",
      "Epoch 261/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 1768427008.0000 - val_loss: 2358653184.0000\n",
      "Epoch 262/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 1760560512.0000 - val_loss: 2352987136.0000\n",
      "Epoch 263/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 1752350464.0000 - val_loss: 2347099648.0000\n",
      "Epoch 264/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 1744028416.0000 - val_loss: 2342296832.0000\n",
      "Epoch 265/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 1736072576.0000 - val_loss: 2336152320.0000\n",
      "Epoch 266/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 1727931392.0000 - val_loss: 2331408384.0000\n",
      "Epoch 267/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 1720234496.0000 - val_loss: 2326986752.0000\n",
      "Epoch 268/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 1712522496.0000 - val_loss: 2321770240.0000\n",
      "Epoch 269/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 1704565632.0000 - val_loss: 2314347264.0000\n",
      "Epoch 270/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 1697203200.0000 - val_loss: 2309007872.0000\n",
      "Epoch 271/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 1689682688.0000 - val_loss: 2303346176.0000\n",
      "Epoch 272/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 1681899264.0000 - val_loss: 2299593216.0000\n",
      "Epoch 273/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 1674394240.0000 - val_loss: 2295217408.0000\n",
      "Epoch 274/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 1667371904.0000 - val_loss: 2289838080.0000\n",
      "Epoch 275/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 1660086016.0000 - val_loss: 2284769792.0000\n",
      "Epoch 276/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 1652660224.0000 - val_loss: 2279811584.0000\n",
      "Epoch 277/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 1645317504.0000 - val_loss: 2275376896.0000\n",
      "Epoch 278/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 1638851200.0000 - val_loss: 2271153152.0000\n",
      "Epoch 279/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 1631249408.0000 - val_loss: 2265929984.0000\n",
      "Epoch 280/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 1624036864.0000 - val_loss: 2261910784.0000\n",
      "Epoch 281/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 1617466112.0000 - val_loss: 2255608064.0000\n",
      "Epoch 282/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 1610312192.0000 - val_loss: 2251512576.0000\n",
      "Epoch 283/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 1603619840.0000 - val_loss: 2247443200.0000\n",
      "Epoch 284/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 1597425280.0000 - val_loss: 2242427648.0000\n",
      "Epoch 285/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 1590415360.0000 - val_loss: 2235725056.0000\n",
      "Epoch 286/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 1583410304.0000 - val_loss: 2232951296.0000\n",
      "Epoch 287/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 1577026432.0000 - val_loss: 2229316864.0000\n",
      "Epoch 288/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 1570973056.0000 - val_loss: 2223190016.0000\n",
      "Epoch 289/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 1564527744.0000 - val_loss: 2222498048.0000\n",
      "Epoch 290/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 1557555840.0000 - val_loss: 2216803328.0000\n",
      "Epoch 291/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 1551260800.0000 - val_loss: 2213175808.0000\n",
      "Epoch 292/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 1545132416.0000 - val_loss: 2207812352.0000\n",
      "Epoch 293/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 1539030400.0000 - val_loss: 2203586816.0000\n",
      "Epoch 294/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 1532861952.0000 - val_loss: 2199301120.0000\n",
      "Epoch 295/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 1527008384.0000 - val_loss: 2194855936.0000\n",
      "Epoch 296/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 1520516864.0000 - val_loss: 2192160512.0000\n",
      "Epoch 297/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 1514569728.0000 - val_loss: 2185475072.0000\n",
      "Epoch 298/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 1508384128.0000 - val_loss: 2182229248.0000\n",
      "Epoch 299/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 1503271936.0000 - val_loss: 2176771840.0000\n",
      "Epoch 300/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 1496940800.0000 - val_loss: 2176429312.0000\n",
      "Epoch 301/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 1490929280.0000 - val_loss: 2171068672.0000\n",
      "Epoch 302/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 1485202432.0000 - val_loss: 2167094016.0000\n",
      "Epoch 303/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 1479673344.0000 - val_loss: 2162666496.0000\n",
      "Epoch 304/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 1473940992.0000 - val_loss: 2160405248.0000\n",
      "Epoch 305/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 1468319360.0000 - val_loss: 2154825216.0000\n",
      "Epoch 306/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 1462565632.0000 - val_loss: 2151598848.0000\n",
      "Epoch 307/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 1457234048.0000 - val_loss: 2149384960.0000\n",
      "Epoch 308/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 1451823104.0000 - val_loss: 2144970112.0000\n",
      "Epoch 309/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 1446292608.0000 - val_loss: 2140845824.0000\n",
      "Epoch 310/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 1440912896.0000 - val_loss: 2136923136.0000\n",
      "Epoch 311/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 1435653760.0000 - val_loss: 2133138048.0000\n",
      "Epoch 312/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 1430082304.0000 - val_loss: 2129534848.0000\n",
      "Epoch 313/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 1425112960.0000 - val_loss: 2125206784.0000\n",
      "Epoch 314/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 1419906176.0000 - val_loss: 2123593088.0000\n",
      "Epoch 315/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 1414643200.0000 - val_loss: 2118157824.0000\n",
      "Epoch 316/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 1409372288.0000 - val_loss: 2114225280.0000\n",
      "Epoch 317/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 1404236544.0000 - val_loss: 2112177024.0000\n",
      "Epoch 318/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 1399122048.0000 - val_loss: 2107752192.0000\n",
      "Epoch 319/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 1394013568.0000 - val_loss: 2104504192.0000\n",
      "Epoch 320/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 1389405184.0000 - val_loss: 2099529984.0000\n",
      "Epoch 321/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 1384295552.0000 - val_loss: 2098390912.0000\n",
      "Epoch 322/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 1379228288.0000 - val_loss: 2094470016.0000\n",
      "Epoch 323/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 1374169728.0000 - val_loss: 2091637760.0000\n",
      "Epoch 324/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 1369532416.0000 - val_loss: 2087645952.0000\n",
      "Epoch 325/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 1365004416.0000 - val_loss: 2084510080.0000\n",
      "Epoch 326/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 1359881600.0000 - val_loss: 2081143040.0000\n",
      "Epoch 327/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 1355359360.0000 - val_loss: 2077332736.0000\n",
      "Epoch 328/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 1350438784.0000 - val_loss: 2075180800.0000\n",
      "Epoch 329/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 1346271616.0000 - val_loss: 2073531648.0000\n",
      "Epoch 330/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 1341181952.0000 - val_loss: 2068771712.0000\n",
      "Epoch 331/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 1336397696.0000 - val_loss: 2065267328.0000\n",
      "Epoch 332/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 1331944960.0000 - val_loss: 2061791488.0000\n",
      "Epoch 333/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 1327612416.0000 - val_loss: 2057111040.0000\n",
      "Epoch 334/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 1322954368.0000 - val_loss: 2054874496.0000\n",
      "Epoch 335/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 1318742272.0000 - val_loss: 2053977472.0000\n",
      "Epoch 336/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 1313784576.0000 - val_loss: 2050528512.0000\n",
      "Epoch 337/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 1309263232.0000 - val_loss: 2044946304.0000\n",
      "Epoch 338/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 1304741760.0000 - val_loss: 2041828608.0000\n",
      "Epoch 339/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 1300860544.0000 - val_loss: 2041497088.0000\n",
      "Epoch 340/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 1295830144.0000 - val_loss: 2036303872.0000\n",
      "Epoch 341/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 1291504256.0000 - val_loss: 2033655680.0000\n",
      "Epoch 342/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 1287112448.0000 - val_loss: 2032188928.0000\n",
      "Epoch 343/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 1282619392.0000 - val_loss: 2027983872.0000\n",
      "Epoch 344/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 1279076992.0000 - val_loss: 2027085440.0000\n",
      "Epoch 345/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 1274521856.0000 - val_loss: 2021141888.0000\n",
      "Epoch 346/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 1269802496.0000 - val_loss: 2020405760.0000\n",
      "Epoch 347/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 1265753344.0000 - val_loss: 2016424448.0000\n",
      "Epoch 348/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 1261668224.0000 - val_loss: 2013218816.0000\n",
      "Epoch 349/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 1257999616.0000 - val_loss: 2011291136.0000\n",
      "Epoch 350/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 1254110208.0000 - val_loss: 2011321856.0000\n",
      "Epoch 351/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 1248661632.0000 - val_loss: 2005908352.0000\n",
      "Epoch 352/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 1245194752.0000 - val_loss: 2002490240.0000\n",
      "Epoch 353/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 1240563328.0000 - val_loss: 2000216832.0000\n",
      "Epoch 354/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 1237188096.0000 - val_loss: 1999226240.0000\n",
      "Epoch 355/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 1233069440.0000 - val_loss: 1994202752.0000\n",
      "Epoch 356/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 1228829056.0000 - val_loss: 1992120704.0000\n",
      "Epoch 357/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 1224625152.0000 - val_loss: 1989241600.0000\n",
      "Epoch 358/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 1220700416.0000 - val_loss: 1985779840.0000\n",
      "Epoch 359/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 1216711680.0000 - val_loss: 1984488832.0000\n",
      "Epoch 360/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 1212852992.0000 - val_loss: 1981751168.0000\n",
      "Epoch 361/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 1208795776.0000 - val_loss: 1977975424.0000\n",
      "Epoch 362/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 1205023616.0000 - val_loss: 1975036032.0000\n",
      "Epoch 363/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 1201152640.0000 - val_loss: 1973365504.0000\n",
      "Epoch 364/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 1197367808.0000 - val_loss: 1970247168.0000\n",
      "Epoch 365/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 1193549312.0000 - val_loss: 1967811584.0000\n",
      "Epoch 366/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 1189783424.0000 - val_loss: 1964427648.0000\n",
      "Epoch 367/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 1186396032.0000 - val_loss: 1963057536.0000\n",
      "Epoch 368/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 1182592896.0000 - val_loss: 1961301888.0000\n",
      "Epoch 369/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 1179009792.0000 - val_loss: 1957286784.0000\n",
      "Epoch 370/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 1175206400.0000 - val_loss: 1957423616.0000\n",
      "Epoch 371/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 1171623040.0000 - val_loss: 1953413632.0000\n",
      "Epoch 372/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 1167906688.0000 - val_loss: 1951789952.0000\n",
      "Epoch 373/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 1164543616.0000 - val_loss: 1949821696.0000\n",
      "Epoch 374/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 1161161088.0000 - val_loss: 1943479552.0000\n",
      "Epoch 375/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 1157023360.0000 - val_loss: 1942525824.0000\n",
      "Epoch 376/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 1153998208.0000 - val_loss: 1940457216.0000\n",
      "Epoch 377/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 1150087936.0000 - val_loss: 1937340416.0000\n",
      "Epoch 378/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 1146669696.0000 - val_loss: 1935800320.0000\n",
      "Epoch 379/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 1143366400.0000 - val_loss: 1934068992.0000\n",
      "Epoch 380/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 1139763072.0000 - val_loss: 1930251392.0000\n",
      "Epoch 381/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 1136548352.0000 - val_loss: 1927609216.0000\n",
      "Epoch 382/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 1133026688.0000 - val_loss: 1926891008.0000\n",
      "Epoch 383/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 1129830912.0000 - val_loss: 1923789056.0000\n",
      "Epoch 384/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 1126452992.0000 - val_loss: 1921090432.0000\n",
      "Epoch 385/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 1123064448.0000 - val_loss: 1917370368.0000\n",
      "Epoch 386/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 1119797376.0000 - val_loss: 1917196928.0000\n",
      "Epoch 387/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 1116384512.0000 - val_loss: 1913507840.0000\n",
      "Epoch 388/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 1113110784.0000 - val_loss: 1911367296.0000\n",
      "Epoch 389/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 1109670016.0000 - val_loss: 1908616576.0000\n",
      "Epoch 390/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 1106249344.0000 - val_loss: 1906921216.0000\n",
      "Epoch 391/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 1103228032.0000 - val_loss: 1902952192.0000\n",
      "Epoch 392/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 1099919872.0000 - val_loss: 1902827904.0000\n",
      "Epoch 393/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 1096793600.0000 - val_loss: 1901054336.0000\n",
      "Epoch 394/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 1093309440.0000 - val_loss: 1897554048.0000\n",
      "Epoch 395/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 1090266112.0000 - val_loss: 1893774720.0000\n",
      "Epoch 396/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 1087137920.0000 - val_loss: 1893511040.0000\n",
      "Epoch 397/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 1084199424.0000 - val_loss: 1890071680.0000\n",
      "Epoch 398/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 1080924032.0000 - val_loss: 1890075264.0000\n",
      "Epoch 399/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 1077603328.0000 - val_loss: 1886305792.0000\n",
      "Epoch 400/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 1074655104.0000 - val_loss: 1884786816.0000\n",
      "Epoch 401/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 1071319104.0000 - val_loss: 1881860608.0000\n",
      "Epoch 402/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 1068290880.0000 - val_loss: 1879317120.0000\n",
      "Epoch 403/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 1065309248.0000 - val_loss: 1878732800.0000\n",
      "Epoch 404/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 1062335104.0000 - val_loss: 1875855744.0000\n",
      "Epoch 405/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 1059495680.0000 - val_loss: 1873678208.0000\n",
      "Epoch 406/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 1056316544.0000 - val_loss: 1871038336.0000\n",
      "Epoch 407/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 1053317120.0000 - val_loss: 1869353600.0000\n",
      "Epoch 408/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 1050317632.0000 - val_loss: 1867551232.0000\n",
      "Epoch 409/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 1047563456.0000 - val_loss: 1865673088.0000\n",
      "Epoch 410/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 1045038976.0000 - val_loss: 1864471168.0000\n",
      "Epoch 411/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 1041490944.0000 - val_loss: 1861023488.0000\n",
      "Epoch 412/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 1038831680.0000 - val_loss: 1857742720.0000\n",
      "Epoch 413/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 1035744512.0000 - val_loss: 1856133376.0000\n",
      "Epoch 414/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 1032941824.0000 - val_loss: 1854633344.0000\n",
      "Epoch 415/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 1030170176.0000 - val_loss: 1851135616.0000\n",
      "Epoch 416/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 1027084096.0000 - val_loss: 1851484416.0000\n",
      "Epoch 417/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 1024718400.0000 - val_loss: 1846636544.0000\n",
      "Epoch 418/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 1021669632.0000 - val_loss: 1845837696.0000\n",
      "Epoch 419/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 1018581376.0000 - val_loss: 1843040512.0000\n",
      "Epoch 420/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 1016100416.0000 - val_loss: 1841642624.0000\n",
      "Epoch 421/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 1012930112.0000 - val_loss: 1838729984.0000\n",
      "Epoch 422/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 1010207040.0000 - val_loss: 1836342912.0000\n",
      "Epoch 423/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 1007627008.0000 - val_loss: 1834930176.0000\n",
      "Epoch 424/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 1005160448.0000 - val_loss: 1833671296.0000\n",
      "Epoch 425/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 1001929984.0000 - val_loss: 1831265024.0000\n",
      "Epoch 426/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 999750080.0000 - val_loss: 1829082368.0000\n",
      "Epoch 427/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 996457472.0000 - val_loss: 1827393792.0000\n",
      "Epoch 428/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 994121216.0000 - val_loss: 1827466752.0000\n",
      "Epoch 429/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 991346432.0000 - val_loss: 1824049152.0000\n",
      "Epoch 430/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 988724032.0000 - val_loss: 1822580096.0000\n",
      "Epoch 431/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 986025600.0000 - val_loss: 1819789568.0000\n",
      "Epoch 432/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 983437568.0000 - val_loss: 1818777216.0000\n",
      "Epoch 433/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 981088704.0000 - val_loss: 1814781056.0000\n",
      "Epoch 434/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 978429952.0000 - val_loss: 1814522624.0000\n",
      "Epoch 435/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 975649216.0000 - val_loss: 1812286336.0000\n",
      "Epoch 436/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 973199040.0000 - val_loss: 1810830976.0000\n",
      "Epoch 437/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 970616448.0000 - val_loss: 1807763456.0000\n",
      "Epoch 438/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 968406592.0000 - val_loss: 1805686912.0000\n",
      "Epoch 439/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 965573184.0000 - val_loss: 1805051648.0000\n",
      "Epoch 440/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 963140032.0000 - val_loss: 1801938432.0000\n",
      "Epoch 441/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 960513216.0000 - val_loss: 1799905408.0000\n",
      "Epoch 442/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 958301632.0000 - val_loss: 1799590400.0000\n",
      "Epoch 443/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 956126720.0000 - val_loss: 1794959488.0000\n",
      "Epoch 444/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 953139648.0000 - val_loss: 1795584896.0000\n",
      "Epoch 445/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 950706752.0000 - val_loss: 1793320576.0000\n",
      "Epoch 446/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 948540672.0000 - val_loss: 1788728064.0000\n",
      "Epoch 447/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 945674496.0000 - val_loss: 1788819200.0000\n",
      "Epoch 448/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 943537024.0000 - val_loss: 1786730240.0000\n",
      "Epoch 449/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 941470784.0000 - val_loss: 1786124160.0000\n",
      "Epoch 450/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 938728896.0000 - val_loss: 1784670080.0000\n",
      "Epoch 451/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 936242048.0000 - val_loss: 1782052736.0000\n",
      "Epoch 452/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 933987840.0000 - val_loss: 1780303104.0000\n",
      "Epoch 453/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 931682880.0000 - val_loss: 1778715776.0000\n",
      "Epoch 454/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 929711040.0000 - val_loss: 1774765952.0000\n",
      "Epoch 455/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 927340224.0000 - val_loss: 1775526528.0000\n",
      "Epoch 456/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 925299840.0000 - val_loss: 1773944576.0000\n",
      "Epoch 457/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 922553984.0000 - val_loss: 1772233344.0000\n",
      "Epoch 458/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 920252672.0000 - val_loss: 1769483392.0000\n",
      "Epoch 459/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 918047360.0000 - val_loss: 1768838656.0000\n",
      "Epoch 460/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 916057088.0000 - val_loss: 1767459072.0000\n",
      "Epoch 461/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 913706880.0000 - val_loss: 1764275584.0000\n",
      "Epoch 462/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 911513472.0000 - val_loss: 1763899392.0000\n",
      "Epoch 463/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 909347520.0000 - val_loss: 1761798144.0000\n",
      "Epoch 464/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 907093952.0000 - val_loss: 1760162944.0000\n",
      "Epoch 465/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 905085760.0000 - val_loss: 1757942912.0000\n",
      "Epoch 466/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 902980032.0000 - val_loss: 1756049408.0000\n",
      "Epoch 467/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 900745344.0000 - val_loss: 1753753728.0000\n",
      "Epoch 468/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 898610304.0000 - val_loss: 1752559360.0000\n",
      "Epoch 469/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 896481536.0000 - val_loss: 1750606336.0000\n",
      "Epoch 470/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 894429952.0000 - val_loss: 1749349888.0000\n",
      "Epoch 471/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 892359808.0000 - val_loss: 1747712768.0000\n",
      "Epoch 472/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 891201088.0000 - val_loss: 1748166016.0000\n",
      "Epoch 473/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 888087232.0000 - val_loss: 1744255488.0000\n",
      "Epoch 474/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 886185088.0000 - val_loss: 1742128512.0000\n",
      "Epoch 475/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 884316544.0000 - val_loss: 1742102144.0000\n",
      "Epoch 476/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 882261056.0000 - val_loss: 1740016128.0000\n",
      "Epoch 477/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 880225664.0000 - val_loss: 1737461120.0000\n",
      "Epoch 478/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 878031488.0000 - val_loss: 1736326016.0000\n",
      "Epoch 479/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 876184896.0000 - val_loss: 1735789056.0000\n",
      "Epoch 480/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 874164352.0000 - val_loss: 1733325696.0000\n",
      "Epoch 481/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 872216192.0000 - val_loss: 1732265088.0000\n",
      "Epoch 482/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 870198528.0000 - val_loss: 1729802112.0000\n",
      "Epoch 483/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 868429952.0000 - val_loss: 1730536576.0000\n",
      "Epoch 484/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 866631232.0000 - val_loss: 1728929920.0000\n",
      "Epoch 485/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 864191296.0000 - val_loss: 1725911424.0000\n",
      "Epoch 486/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 862509952.0000 - val_loss: 1723416960.0000\n",
      "Epoch 487/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 860560256.0000 - val_loss: 1723310208.0000\n",
      "Epoch 488/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 858463744.0000 - val_loss: 1720237440.0000\n",
      "Epoch 489/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 856966400.0000 - val_loss: 1717605376.0000\n",
      "Epoch 490/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 855316992.0000 - val_loss: 1717383808.0000\n",
      "Epoch 491/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 852645568.0000 - val_loss: 1716464512.0000\n",
      "Epoch 492/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 850835200.0000 - val_loss: 1714239232.0000\n",
      "Epoch 493/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 848957440.0000 - val_loss: 1712997760.0000\n",
      "Epoch 494/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 847218624.0000 - val_loss: 1711110784.0000\n",
      "Epoch 495/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 845796928.0000 - val_loss: 1709431424.0000\n",
      "Epoch 496/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 843412416.0000 - val_loss: 1709932928.0000\n",
      "Epoch 497/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 841578432.0000 - val_loss: 1707436288.0000\n",
      "Epoch 498/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 839842560.0000 - val_loss: 1705015680.0000\n",
      "Epoch 499/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 838169984.0000 - val_loss: 1703807360.0000\n",
      "Epoch 500/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 836164416.0000 - val_loss: 1702768128.0000\n",
      "Epoch 501/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 834109760.0000 - val_loss: 1699571072.0000\n",
      "Epoch 502/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 832303744.0000 - val_loss: 1698809472.0000\n",
      "Epoch 503/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 830468544.0000 - val_loss: 1697934848.0000\n",
      "Epoch 504/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 828760576.0000 - val_loss: 1695706880.0000\n",
      "Epoch 505/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 827072128.0000 - val_loss: 1694322816.0000\n",
      "Epoch 506/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 825470848.0000 - val_loss: 1693062144.0000\n",
      "Epoch 507/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 823650112.0000 - val_loss: 1691514880.0000\n",
      "Epoch 508/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 821820288.0000 - val_loss: 1690593152.0000\n",
      "Epoch 509/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 820071040.0000 - val_loss: 1689386496.0000\n",
      "Epoch 510/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 818432512.0000 - val_loss: 1687879936.0000\n",
      "Epoch 511/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 816712768.0000 - val_loss: 1686145152.0000\n",
      "Epoch 512/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 814884928.0000 - val_loss: 1685842304.0000\n",
      "Epoch 513/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 813046272.0000 - val_loss: 1684682496.0000\n",
      "Epoch 514/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 811390272.0000 - val_loss: 1683968896.0000\n",
      "Epoch 515/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 809782784.0000 - val_loss: 1682768640.0000\n",
      "Epoch 516/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 807900864.0000 - val_loss: 1679876224.0000\n",
      "Epoch 517/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 806531008.0000 - val_loss: 1677217792.0000\n",
      "Epoch 518/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 804681600.0000 - val_loss: 1677077888.0000\n",
      "Epoch 519/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 802876224.0000 - val_loss: 1676743808.0000\n",
      "Epoch 520/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 801403456.0000 - val_loss: 1675084672.0000\n",
      "Epoch 521/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 799795200.0000 - val_loss: 1673926144.0000\n",
      "Epoch 522/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 798150592.0000 - val_loss: 1671859328.0000\n",
      "Epoch 523/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 796566720.0000 - val_loss: 1671103360.0000\n",
      "Epoch 524/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 794869952.0000 - val_loss: 1669718912.0000\n",
      "Epoch 525/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 793426048.0000 - val_loss: 1669542784.0000\n",
      "Epoch 526/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 791839808.0000 - val_loss: 1665610240.0000\n",
      "Epoch 527/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 790156800.0000 - val_loss: 1666121344.0000\n",
      "Epoch 528/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 788577664.0000 - val_loss: 1665088512.0000\n",
      "Epoch 529/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 787066560.0000 - val_loss: 1662788352.0000\n",
      "Epoch 530/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 785408128.0000 - val_loss: 1663117696.0000\n",
      "Epoch 531/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 783922688.0000 - val_loss: 1660576128.0000\n",
      "Epoch 532/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 782606784.0000 - val_loss: 1661157504.0000\n",
      "Epoch 533/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 780528576.0000 - val_loss: 1658104192.0000\n",
      "Epoch 534/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 779651008.0000 - val_loss: 1654977408.0000\n",
      "Epoch 535/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 777830400.0000 - val_loss: 1654803584.0000\n",
      "Epoch 536/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 776522368.0000 - val_loss: 1654577664.0000\n",
      "Epoch 537/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 774514240.0000 - val_loss: 1653379328.0000\n",
      "Epoch 538/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 773234304.0000 - val_loss: 1653211520.0000\n",
      "Epoch 539/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 771624960.0000 - val_loss: 1650281216.0000\n",
      "Epoch 540/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 770098304.0000 - val_loss: 1650707840.0000\n",
      "Epoch 541/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 768573696.0000 - val_loss: 1649176192.0000\n",
      "Epoch 542/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 767494848.0000 - val_loss: 1647057536.0000\n",
      "Epoch 543/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 765616384.0000 - val_loss: 1646325760.0000\n",
      "Epoch 544/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 764266112.0000 - val_loss: 1644483456.0000\n",
      "Epoch 545/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 762603328.0000 - val_loss: 1643847040.0000\n",
      "Epoch 546/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 761477120.0000 - val_loss: 1642198528.0000\n",
      "Epoch 547/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 759966656.0000 - val_loss: 1641294208.0000\n",
      "Epoch 548/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 758368704.0000 - val_loss: 1639875968.0000\n",
      "Epoch 549/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 756892480.0000 - val_loss: 1638946560.0000\n",
      "Epoch 550/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 755369920.0000 - val_loss: 1639535232.0000\n",
      "Epoch 551/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 754044928.0000 - val_loss: 1636020224.0000\n",
      "Epoch 552/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 752903808.0000 - val_loss: 1635904640.0000\n",
      "Epoch 553/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 750907968.0000 - val_loss: 1635228928.0000\n",
      "Epoch 554/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 749535872.0000 - val_loss: 1632114944.0000\n",
      "Epoch 555/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 748135232.0000 - val_loss: 1631978880.0000\n",
      "Epoch 556/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 746615488.0000 - val_loss: 1630832896.0000\n",
      "Epoch 557/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 745369344.0000 - val_loss: 1629571200.0000\n",
      "Epoch 558/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 743805568.0000 - val_loss: 1629566208.0000\n",
      "Epoch 559/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 742336512.0000 - val_loss: 1627176064.0000\n",
      "Epoch 560/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 741005248.0000 - val_loss: 1626107008.0000\n",
      "Epoch 561/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 739534848.0000 - val_loss: 1625851904.0000\n",
      "Epoch 562/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 738182272.0000 - val_loss: 1623713536.0000\n",
      "Epoch 563/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 736739584.0000 - val_loss: 1623267968.0000\n",
      "Epoch 564/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 735451136.0000 - val_loss: 1621914240.0000\n",
      "Epoch 565/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 734162816.0000 - val_loss: 1621137408.0000\n",
      "Epoch 566/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 732793728.0000 - val_loss: 1620219776.0000\n",
      "Epoch 567/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 731607168.0000 - val_loss: 1618171392.0000\n",
      "Epoch 568/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 730082432.0000 - val_loss: 1618118912.0000\n",
      "Epoch 569/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 729040960.0000 - val_loss: 1617762560.0000\n",
      "Epoch 570/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 727410560.0000 - val_loss: 1615613056.0000\n",
      "Epoch 571/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 726041984.0000 - val_loss: 1614553472.0000\n",
      "Epoch 572/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 724767616.0000 - val_loss: 1614278528.0000\n",
      "Epoch 573/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 723500736.0000 - val_loss: 1612175744.0000\n",
      "Epoch 574/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 722086784.0000 - val_loss: 1612974592.0000\n",
      "Epoch 575/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 720937152.0000 - val_loss: 1609885056.0000\n",
      "Epoch 576/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 719544064.0000 - val_loss: 1611133056.0000\n",
      "Epoch 577/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 718089984.0000 - val_loss: 1609678080.0000\n",
      "Epoch 578/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 716711360.0000 - val_loss: 1606937344.0000\n",
      "Epoch 579/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 715536576.0000 - val_loss: 1606195328.0000\n",
      "Epoch 580/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 714386816.0000 - val_loss: 1604518656.0000\n",
      "Epoch 581/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 713156672.0000 - val_loss: 1604600960.0000\n",
      "Epoch 582/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 711774976.0000 - val_loss: 1603910272.0000\n",
      "Epoch 583/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 710856064.0000 - val_loss: 1601753600.0000\n",
      "Epoch 584/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 709061248.0000 - val_loss: 1601613184.0000\n",
      "Epoch 585/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 708336192.0000 - val_loss: 1603063296.0000\n",
      "Epoch 586/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 706903168.0000 - val_loss: 1599557632.0000\n",
      "Epoch 587/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 705301568.0000 - val_loss: 1599260928.0000\n",
      "Epoch 588/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 703962496.0000 - val_loss: 1597862272.0000\n",
      "Epoch 589/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 702796736.0000 - val_loss: 1596169344.0000\n",
      "Epoch 590/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 701834944.0000 - val_loss: 1595471360.0000\n",
      "Epoch 591/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 700713472.0000 - val_loss: 1595928064.0000\n",
      "Epoch 592/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 699340416.0000 - val_loss: 1591960192.0000\n",
      "Epoch 593/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 697957568.0000 - val_loss: 1592800256.0000\n",
      "Epoch 594/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 696547584.0000 - val_loss: 1591682816.0000\n",
      "Epoch 595/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 695404864.0000 - val_loss: 1590507648.0000\n",
      "Epoch 596/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 694518464.0000 - val_loss: 1589465088.0000\n",
      "Epoch 597/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 693070528.0000 - val_loss: 1589382272.0000\n",
      "Epoch 598/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 691819904.0000 - val_loss: 1589679104.0000\n",
      "Epoch 599/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 691541824.0000 - val_loss: 1586020864.0000\n",
      "Epoch 600/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 689450880.0000 - val_loss: 1587137536.0000\n",
      "Epoch 601/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 688263168.0000 - val_loss: 1586132480.0000\n",
      "Epoch 602/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 687108288.0000 - val_loss: 1584814848.0000\n",
      "Epoch 603/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 686175552.0000 - val_loss: 1583592192.0000\n",
      "Epoch 604/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 685223808.0000 - val_loss: 1582781952.0000\n",
      "Epoch 605/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 683857984.0000 - val_loss: 1582596224.0000\n",
      "Epoch 606/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 682577472.0000 - val_loss: 1581096448.0000\n",
      "Epoch 607/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 681487936.0000 - val_loss: 1581099008.0000\n",
      "Epoch 608/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 680131328.0000 - val_loss: 1579848832.0000\n",
      "Epoch 609/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 679031232.0000 - val_loss: 1578050560.0000\n",
      "Epoch 610/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 678001216.0000 - val_loss: 1577798016.0000\n",
      "Epoch 611/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 677135488.0000 - val_loss: 1578388480.0000\n",
      "Epoch 612/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 675788480.0000 - val_loss: 1577131904.0000\n",
      "Epoch 613/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 674610432.0000 - val_loss: 1576157696.0000\n",
      "Epoch 614/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 673554112.0000 - val_loss: 1573710208.0000\n",
      "Epoch 615/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 672588800.0000 - val_loss: 1571462784.0000\n",
      "Epoch 616/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 671411456.0000 - val_loss: 1571505664.0000\n",
      "Epoch 617/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 670157248.0000 - val_loss: 1572320128.0000\n",
      "Epoch 618/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 669334848.0000 - val_loss: 1571337088.0000\n",
      "Epoch 619/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 668103872.0000 - val_loss: 1570883840.0000\n",
      "Epoch 620/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 666876032.0000 - val_loss: 1569072000.0000\n",
      "Epoch 621/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 665883712.0000 - val_loss: 1569316736.0000\n",
      "Epoch 622/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 665010112.0000 - val_loss: 1567733504.0000\n",
      "Epoch 623/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 663995968.0000 - val_loss: 1569279488.0000\n",
      "Epoch 624/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 663006976.0000 - val_loss: 1565288960.0000\n",
      "Epoch 625/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 661761216.0000 - val_loss: 1565681152.0000\n",
      "Epoch 626/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 660564224.0000 - val_loss: 1564296576.0000\n",
      "Epoch 627/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 659900032.0000 - val_loss: 1565188864.0000\n",
      "Epoch 628/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 658342592.0000 - val_loss: 1562378112.0000\n",
      "Epoch 629/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 657495424.0000 - val_loss: 1561591552.0000\n",
      "Epoch 630/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 656716032.0000 - val_loss: 1562545152.0000\n",
      "Epoch 631/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 655380352.0000 - val_loss: 1560886784.0000\n",
      "Epoch 632/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 654330624.0000 - val_loss: 1560429952.0000\n",
      "Epoch 633/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 653517696.0000 - val_loss: 1558794880.0000\n",
      "Epoch 634/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 652418816.0000 - val_loss: 1560212992.0000\n",
      "Epoch 635/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 651108800.0000 - val_loss: 1557423488.0000\n",
      "Epoch 636/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 650314688.0000 - val_loss: 1557405184.0000\n",
      "Epoch 637/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 649551552.0000 - val_loss: 1557356672.0000\n",
      "Epoch 638/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 648296000.0000 - val_loss: 1554865664.0000\n",
      "Epoch 639/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 647255744.0000 - val_loss: 1555553152.0000\n",
      "Epoch 640/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 646248384.0000 - val_loss: 1554784384.0000\n",
      "Epoch 641/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 645138432.0000 - val_loss: 1553327232.0000\n",
      "Epoch 642/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 644018368.0000 - val_loss: 1552892032.0000\n",
      "Epoch 643/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 643061440.0000 - val_loss: 1552405760.0000\n",
      "Epoch 644/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 642126336.0000 - val_loss: 1551343744.0000\n",
      "Epoch 645/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 640976448.0000 - val_loss: 1551646208.0000\n",
      "Epoch 646/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 640341056.0000 - val_loss: 1551511040.0000\n",
      "Epoch 647/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 639131136.0000 - val_loss: 1550027776.0000\n",
      "Epoch 648/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 637954752.0000 - val_loss: 1548497408.0000\n",
      "Epoch 649/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 636958784.0000 - val_loss: 1547668096.0000\n",
      "Epoch 650/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 636286720.0000 - val_loss: 1547099648.0000\n",
      "Epoch 651/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 635299776.0000 - val_loss: 1547633792.0000\n",
      "Epoch 652/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 634433920.0000 - val_loss: 1545269248.0000\n",
      "Epoch 653/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 633329536.0000 - val_loss: 1545794432.0000\n",
      "Epoch 654/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 632110080.0000 - val_loss: 1544436992.0000\n",
      "Epoch 655/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 631215744.0000 - val_loss: 1543346176.0000\n",
      "Epoch 656/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 630230336.0000 - val_loss: 1542720768.0000\n",
      "Epoch 657/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 629274944.0000 - val_loss: 1542942848.0000\n",
      "Epoch 658/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 628169600.0000 - val_loss: 1541817344.0000\n",
      "Epoch 659/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 627329216.0000 - val_loss: 1540118912.0000\n",
      "Epoch 660/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 626440256.0000 - val_loss: 1539635584.0000\n",
      "Epoch 661/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 625490816.0000 - val_loss: 1540116352.0000\n",
      "Epoch 662/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 624456256.0000 - val_loss: 1538930304.0000\n",
      "Epoch 663/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 623483904.0000 - val_loss: 1538907264.0000\n",
      "Epoch 664/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 622621760.0000 - val_loss: 1538432128.0000\n",
      "Epoch 665/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 621493504.0000 - val_loss: 1537708160.0000\n",
      "Epoch 666/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 620764416.0000 - val_loss: 1536083328.0000\n",
      "Epoch 667/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 619635584.0000 - val_loss: 1535260416.0000\n",
      "Epoch 668/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 618925440.0000 - val_loss: 1535935872.0000\n",
      "Epoch 669/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 617680896.0000 - val_loss: 1533390976.0000\n",
      "Epoch 670/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 617029312.0000 - val_loss: 1532651392.0000\n",
      "Epoch 671/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 616539200.0000 - val_loss: 1533911552.0000\n",
      "Epoch 672/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 615353024.0000 - val_loss: 1530978176.0000\n",
      "Epoch 673/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 614290816.0000 - val_loss: 1531503872.0000\n",
      "Epoch 674/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 613314816.0000 - val_loss: 1530230144.0000\n",
      "Epoch 675/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 612479488.0000 - val_loss: 1530355200.0000\n",
      "Epoch 676/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 611602560.0000 - val_loss: 1530353664.0000\n",
      "Epoch 677/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 610580736.0000 - val_loss: 1529665280.0000\n",
      "Epoch 678/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 609841024.0000 - val_loss: 1528339712.0000\n",
      "Epoch 679/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 608879872.0000 - val_loss: 1528150016.0000\n",
      "Epoch 680/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 608082816.0000 - val_loss: 1527880192.0000\n",
      "Epoch 681/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 607239808.0000 - val_loss: 1526742400.0000\n",
      "Epoch 682/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 606137088.0000 - val_loss: 1526625152.0000\n",
      "Epoch 683/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 605470848.0000 - val_loss: 1524404224.0000\n",
      "Epoch 684/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 604440256.0000 - val_loss: 1525268352.0000\n",
      "Epoch 685/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 603736384.0000 - val_loss: 1524599552.0000\n",
      "Epoch 686/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 602823616.0000 - val_loss: 1523845248.0000\n",
      "Epoch 687/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 601848576.0000 - val_loss: 1522974464.0000\n",
      "Epoch 688/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 600922880.0000 - val_loss: 1522103424.0000\n",
      "Epoch 689/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 600292736.0000 - val_loss: 1520582656.0000\n",
      "Epoch 690/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 599182400.0000 - val_loss: 1520342528.0000\n",
      "Epoch 691/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 598484224.0000 - val_loss: 1520837248.0000\n",
      "Epoch 692/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 597585792.0000 - val_loss: 1520532608.0000\n",
      "Epoch 693/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 596601280.0000 - val_loss: 1518825728.0000\n",
      "Epoch 694/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 595925888.0000 - val_loss: 1518272000.0000\n",
      "Epoch 695/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 595023424.0000 - val_loss: 1517993600.0000\n",
      "Epoch 696/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 594216448.0000 - val_loss: 1517544064.0000\n",
      "Epoch 697/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 593371392.0000 - val_loss: 1517473024.0000\n",
      "Epoch 698/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 592753984.0000 - val_loss: 1517981056.0000\n",
      "Epoch 699/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 591664704.0000 - val_loss: 1515292416.0000\n",
      "Epoch 700/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 590772480.0000 - val_loss: 1515056128.0000\n",
      "Epoch 701/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 589777920.0000 - val_loss: 1514162688.0000\n",
      "Epoch 702/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 588961728.0000 - val_loss: 1513770368.0000\n",
      "Epoch 703/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 588325120.0000 - val_loss: 1512683264.0000\n",
      "Epoch 704/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 587409472.0000 - val_loss: 1513077632.0000\n",
      "Epoch 705/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 586467968.0000 - val_loss: 1512285184.0000\n",
      "Epoch 706/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 585698624.0000 - val_loss: 1511599872.0000\n",
      "Epoch 707/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 584892032.0000 - val_loss: 1510901248.0000\n",
      "Epoch 708/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 583990016.0000 - val_loss: 1511115392.0000\n",
      "Epoch 709/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 583525696.0000 - val_loss: 1509198208.0000\n",
      "Epoch 710/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 582386816.0000 - val_loss: 1510089600.0000\n",
      "Epoch 711/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 581883456.0000 - val_loss: 1509530752.0000\n",
      "Epoch 712/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 580785344.0000 - val_loss: 1509048832.0000\n",
      "Epoch 713/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 579854528.0000 - val_loss: 1507359744.0000\n",
      "Epoch 714/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 579022144.0000 - val_loss: 1506472704.0000\n",
      "Epoch 715/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 578493312.0000 - val_loss: 1505390208.0000\n",
      "Epoch 716/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 577728192.0000 - val_loss: 1505904256.0000\n",
      "Epoch 717/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 576942080.0000 - val_loss: 1505972224.0000\n",
      "Epoch 718/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 576648768.0000 - val_loss: 1503319808.0000\n",
      "Epoch 719/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 575622912.0000 - val_loss: 1502939904.0000\n",
      "Epoch 720/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 574405504.0000 - val_loss: 1502598272.0000\n",
      "Epoch 721/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 573915712.0000 - val_loss: 1502861824.0000\n",
      "Epoch 722/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 573207680.0000 - val_loss: 1501125120.0000\n",
      "Epoch 723/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 572168768.0000 - val_loss: 1501961344.0000\n",
      "Epoch 724/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 571719936.0000 - val_loss: 1501541248.0000\n",
      "Epoch 725/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 570537920.0000 - val_loss: 1498724864.0000\n",
      "Epoch 726/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 570002176.0000 - val_loss: 1497731456.0000\n",
      "Epoch 727/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 568837888.0000 - val_loss: 1499173760.0000\n",
      "Epoch 728/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 568229952.0000 - val_loss: 1498712064.0000\n",
      "Epoch 729/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 567429184.0000 - val_loss: 1498127360.0000\n",
      "Epoch 730/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 566924992.0000 - val_loss: 1498015104.0000\n",
      "Epoch 731/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 566075776.0000 - val_loss: 1495998976.0000\n",
      "Epoch 732/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 565311744.0000 - val_loss: 1495090560.0000\n",
      "Epoch 733/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 564350464.0000 - val_loss: 1495061632.0000\n",
      "Epoch 734/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 563745408.0000 - val_loss: 1494609792.0000\n",
      "Epoch 735/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 563300544.0000 - val_loss: 1495477632.0000\n",
      "Epoch 736/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 562340224.0000 - val_loss: 1493833856.0000\n",
      "Epoch 737/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 561655360.0000 - val_loss: 1492129152.0000\n",
      "Epoch 738/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 560753984.0000 - val_loss: 1492153216.0000\n",
      "Epoch 739/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 560195584.0000 - val_loss: 1491134720.0000\n",
      "Epoch 740/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 559434368.0000 - val_loss: 1492036608.0000\n",
      "Epoch 741/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 558563456.0000 - val_loss: 1489963776.0000\n",
      "Epoch 742/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 557774976.0000 - val_loss: 1490174080.0000\n",
      "Epoch 743/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 557050304.0000 - val_loss: 1490242432.0000\n",
      "Epoch 744/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 556832768.0000 - val_loss: 1488922496.0000\n",
      "Epoch 745/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 555663232.0000 - val_loss: 1488086528.0000\n",
      "Epoch 746/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 555109376.0000 - val_loss: 1487317248.0000\n",
      "Epoch 747/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 554354752.0000 - val_loss: 1488148224.0000\n",
      "Epoch 748/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 553485312.0000 - val_loss: 1486955392.0000\n",
      "Epoch 749/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 552905536.0000 - val_loss: 1486204032.0000\n",
      "Epoch 750/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 552262080.0000 - val_loss: 1486694400.0000\n",
      "Epoch 751/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 551642240.0000 - val_loss: 1484240640.0000\n",
      "Epoch 752/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 550900992.0000 - val_loss: 1484247552.0000\n",
      "Epoch 753/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 550021568.0000 - val_loss: 1484000384.0000\n",
      "Epoch 754/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 549392064.0000 - val_loss: 1483490688.0000\n",
      "Epoch 755/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 548666368.0000 - val_loss: 1482853760.0000\n",
      "Epoch 756/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 548271296.0000 - val_loss: 1482807040.0000\n",
      "Epoch 757/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 547541696.0000 - val_loss: 1481760896.0000\n",
      "Epoch 758/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 546791232.0000 - val_loss: 1481491072.0000\n",
      "Epoch 759/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 546145472.0000 - val_loss: 1480560384.0000\n",
      "Epoch 760/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 545519360.0000 - val_loss: 1481643264.0000\n",
      "Epoch 761/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 544991552.0000 - val_loss: 1478854912.0000\n",
      "Epoch 762/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 544360960.0000 - val_loss: 1478237824.0000\n",
      "Epoch 763/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 543227840.0000 - val_loss: 1478258432.0000\n",
      "Epoch 764/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 542792384.0000 - val_loss: 1477367808.0000\n",
      "Epoch 765/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 542168960.0000 - val_loss: 1476973824.0000\n",
      "Epoch 766/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 542051648.0000 - val_loss: 1478780544.0000\n",
      "Epoch 767/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 540732032.0000 - val_loss: 1475177856.0000\n",
      "Epoch 768/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 540195264.0000 - val_loss: 1475222016.0000\n",
      "Epoch 769/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 539571840.0000 - val_loss: 1474985088.0000\n",
      "Epoch 770/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 538827648.0000 - val_loss: 1474407552.0000\n",
      "Epoch 771/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 538268544.0000 - val_loss: 1473488896.0000\n",
      "Epoch 772/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 537351936.0000 - val_loss: 1472515712.0000\n",
      "Epoch 773/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 537160320.0000 - val_loss: 1472019072.0000\n",
      "Epoch 774/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 536277152.0000 - val_loss: 1471269248.0000\n",
      "Epoch 775/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 535556928.0000 - val_loss: 1470658304.0000\n",
      "Epoch 776/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 534894016.0000 - val_loss: 1471683328.0000\n",
      "Epoch 777/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 534156000.0000 - val_loss: 1469968896.0000\n",
      "Epoch 778/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 533744192.0000 - val_loss: 1470946432.0000\n",
      "Epoch 779/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 533046368.0000 - val_loss: 1468431488.0000\n",
      "Epoch 780/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 532226048.0000 - val_loss: 1468946304.0000\n",
      "Epoch 781/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 531915712.0000 - val_loss: 1469402240.0000\n",
      "Epoch 782/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 530862016.0000 - val_loss: 1468162432.0000\n",
      "Epoch 783/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 530396864.0000 - val_loss: 1466706048.0000\n",
      "Epoch 784/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 529816768.0000 - val_loss: 1466191360.0000\n",
      "Epoch 785/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 529276480.0000 - val_loss: 1466938240.0000\n",
      "Epoch 786/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 528691808.0000 - val_loss: 1466422400.0000\n",
      "Epoch 787/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 528059840.0000 - val_loss: 1465988992.0000\n",
      "Epoch 788/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 527349440.0000 - val_loss: 1465057024.0000\n",
      "Epoch 789/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 526830496.0000 - val_loss: 1465242624.0000\n",
      "Epoch 790/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 526256544.0000 - val_loss: 1463048832.0000\n",
      "Epoch 791/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 525575200.0000 - val_loss: 1463190912.0000\n",
      "Epoch 792/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 525044864.0000 - val_loss: 1463774336.0000\n",
      "Epoch 793/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 524185952.0000 - val_loss: 1463139968.0000\n",
      "Epoch 794/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 523866400.0000 - val_loss: 1462384000.0000\n",
      "Epoch 795/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 523147904.0000 - val_loss: 1461129600.0000\n",
      "Epoch 796/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 522588896.0000 - val_loss: 1461797376.0000\n",
      "Epoch 797/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 521791232.0000 - val_loss: 1461124608.0000\n",
      "Epoch 798/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 521240448.0000 - val_loss: 1459509632.0000\n",
      "Epoch 799/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 520677408.0000 - val_loss: 1458837504.0000\n",
      "Epoch 800/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 520167776.0000 - val_loss: 1458456832.0000\n",
      "Epoch 801/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 519827616.0000 - val_loss: 1459107968.0000\n",
      "Epoch 802/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 518910240.0000 - val_loss: 1459158528.0000\n",
      "Epoch 803/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 518385440.0000 - val_loss: 1456914304.0000\n",
      "Epoch 804/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 517777280.0000 - val_loss: 1456564480.0000\n",
      "Epoch 805/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 517284640.0000 - val_loss: 1457564416.0000\n",
      "Epoch 806/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 516492704.0000 - val_loss: 1456017664.0000\n",
      "Epoch 807/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 515863424.0000 - val_loss: 1457056640.0000\n",
      "Epoch 808/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 515202560.0000 - val_loss: 1455730944.0000\n",
      "Epoch 809/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 514738592.0000 - val_loss: 1454753920.0000\n",
      "Epoch 810/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 514229568.0000 - val_loss: 1455469184.0000\n",
      "Epoch 811/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 513561088.0000 - val_loss: 1454132480.0000\n",
      "Epoch 812/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 513070688.0000 - val_loss: 1454511872.0000\n",
      "Epoch 813/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 512382656.0000 - val_loss: 1453556096.0000\n",
      "Epoch 814/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 511803968.0000 - val_loss: 1452190336.0000\n",
      "Epoch 815/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 511917856.0000 - val_loss: 1452546048.0000\n",
      "Epoch 816/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 510666848.0000 - val_loss: 1451794304.0000\n",
      "Epoch 817/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 510262784.0000 - val_loss: 1450841984.0000\n",
      "Epoch 818/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 509981248.0000 - val_loss: 1449807360.0000\n",
      "Epoch 819/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 509120736.0000 - val_loss: 1450771200.0000\n",
      "Epoch 820/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 508571488.0000 - val_loss: 1450062336.0000\n",
      "Epoch 821/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 507937664.0000 - val_loss: 1449127040.0000\n",
      "Epoch 822/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 508252896.0000 - val_loss: 1449730816.0000\n",
      "Epoch 823/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 506730528.0000 - val_loss: 1448072960.0000\n",
      "Epoch 824/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 506307968.0000 - val_loss: 1448110976.0000\n",
      "Epoch 825/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 505740736.0000 - val_loss: 1446678016.0000\n",
      "Epoch 826/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 505187104.0000 - val_loss: 1448280064.0000\n",
      "Epoch 827/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 504836320.0000 - val_loss: 1446812288.0000\n",
      "Epoch 828/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 504125312.0000 - val_loss: 1447271936.0000\n",
      "Epoch 829/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 503749376.0000 - val_loss: 1447143424.0000\n",
      "Epoch 830/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 502964896.0000 - val_loss: 1445442688.0000\n",
      "Epoch 831/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 502567072.0000 - val_loss: 1444350592.0000\n",
      "Epoch 832/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 502132960.0000 - val_loss: 1445779584.0000\n",
      "Epoch 833/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 501576416.0000 - val_loss: 1443623808.0000\n",
      "Epoch 834/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 500880320.0000 - val_loss: 1442990464.0000\n",
      "Epoch 835/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 500427616.0000 - val_loss: 1443019520.0000\n",
      "Epoch 836/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 499861824.0000 - val_loss: 1442797696.0000\n",
      "Epoch 837/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 499274080.0000 - val_loss: 1442456832.0000\n",
      "Epoch 838/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 498744896.0000 - val_loss: 1442897152.0000\n",
      "Epoch 839/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 498212864.0000 - val_loss: 1440691840.0000\n",
      "Epoch 840/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 497529632.0000 - val_loss: 1441115648.0000\n",
      "Epoch 841/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 497659008.0000 - val_loss: 1439848960.0000\n",
      "Epoch 842/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 496497888.0000 - val_loss: 1440512640.0000\n",
      "Epoch 843/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 496138816.0000 - val_loss: 1440525440.0000\n",
      "Epoch 844/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 495489184.0000 - val_loss: 1439794816.0000\n",
      "Epoch 845/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 494930400.0000 - val_loss: 1439030784.0000\n",
      "Epoch 846/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 494410304.0000 - val_loss: 1437773312.0000\n",
      "Epoch 847/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 493829696.0000 - val_loss: 1437728000.0000\n",
      "Epoch 848/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 493408384.0000 - val_loss: 1436948864.0000\n",
      "Epoch 849/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 492925888.0000 - val_loss: 1436610688.0000\n",
      "Epoch 850/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 492483808.0000 - val_loss: 1436990080.0000\n",
      "Epoch 851/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 492007648.0000 - val_loss: 1436388864.0000\n",
      "Epoch 852/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 491634848.0000 - val_loss: 1437192192.0000\n",
      "Epoch 853/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 491082112.0000 - val_loss: 1434446080.0000\n",
      "Epoch 854/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 490326816.0000 - val_loss: 1435001344.0000\n",
      "Epoch 855/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 489912896.0000 - val_loss: 1433704192.0000\n",
      "Epoch 856/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 489273440.0000 - val_loss: 1433723136.0000\n",
      "Epoch 857/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 489119232.0000 - val_loss: 1433714176.0000\n",
      "Epoch 858/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 488400768.0000 - val_loss: 1431569664.0000\n",
      "Epoch 859/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 488034304.0000 - val_loss: 1432393600.0000\n",
      "Epoch 860/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 487282144.0000 - val_loss: 1431065472.0000\n",
      "Epoch 861/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 486732736.0000 - val_loss: 1430873856.0000\n",
      "Epoch 862/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 486386464.0000 - val_loss: 1431335808.0000\n",
      "Epoch 863/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 485685216.0000 - val_loss: 1430233344.0000\n",
      "Epoch 864/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 485230624.0000 - val_loss: 1430971136.0000\n",
      "Epoch 865/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 484923424.0000 - val_loss: 1430200448.0000\n",
      "Epoch 866/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 484761600.0000 - val_loss: 1428029440.0000\n",
      "Epoch 867/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 483938656.0000 - val_loss: 1428712064.0000\n",
      "Epoch 868/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 483209728.0000 - val_loss: 1427676544.0000\n",
      "Epoch 869/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 482732800.0000 - val_loss: 1427580288.0000\n",
      "Epoch 870/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 482149536.0000 - val_loss: 1426672768.0000\n",
      "Epoch 871/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 481914592.0000 - val_loss: 1426201088.0000\n",
      "Epoch 872/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 481440544.0000 - val_loss: 1426226688.0000\n",
      "Epoch 873/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 480695904.0000 - val_loss: 1426471936.0000\n",
      "Epoch 874/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 480170560.0000 - val_loss: 1426143360.0000\n",
      "Epoch 875/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 479907904.0000 - val_loss: 1426180480.0000\n",
      "Epoch 876/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 479174880.0000 - val_loss: 1423943168.0000\n",
      "Epoch 877/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 478863136.0000 - val_loss: 1423224576.0000\n",
      "Epoch 878/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 478539648.0000 - val_loss: 1424349696.0000\n",
      "Epoch 879/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 478028896.0000 - val_loss: 1423137664.0000\n",
      "Epoch 880/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 477361984.0000 - val_loss: 1422889216.0000\n",
      "Epoch 881/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 476943680.0000 - val_loss: 1422247040.0000\n",
      "Epoch 882/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 476573536.0000 - val_loss: 1420519680.0000\n",
      "Epoch 883/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 476142784.0000 - val_loss: 1419469952.0000\n",
      "Epoch 884/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 475488032.0000 - val_loss: 1421081984.0000\n",
      "Epoch 885/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 474983712.0000 - val_loss: 1420435968.0000\n",
      "Epoch 886/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 474373696.0000 - val_loss: 1419262592.0000\n",
      "Epoch 887/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 474136128.0000 - val_loss: 1419811200.0000\n",
      "Epoch 888/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 473515392.0000 - val_loss: 1419441280.0000\n",
      "Epoch 889/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 472954336.0000 - val_loss: 1417448576.0000\n",
      "Epoch 890/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 472728576.0000 - val_loss: 1417186048.0000\n",
      "Epoch 891/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 472094912.0000 - val_loss: 1417399936.0000\n",
      "Epoch 892/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 471504352.0000 - val_loss: 1417317376.0000\n",
      "Epoch 893/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 471221696.0000 - val_loss: 1417658496.0000\n",
      "Epoch 894/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 470808704.0000 - val_loss: 1415815040.0000\n",
      "Epoch 895/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 470310560.0000 - val_loss: 1415899392.0000\n",
      "Epoch 896/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 469709536.0000 - val_loss: 1415784448.0000\n",
      "Epoch 897/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 469276704.0000 - val_loss: 1415214464.0000\n",
      "Epoch 898/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 468880512.0000 - val_loss: 1414508928.0000\n",
      "Epoch 899/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 468506624.0000 - val_loss: 1414546944.0000\n",
      "Epoch 900/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 468021120.0000 - val_loss: 1413633152.0000\n",
      "Epoch 901/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 467577376.0000 - val_loss: 1414222976.0000\n",
      "Epoch 902/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 467018848.0000 - val_loss: 1412918784.0000\n",
      "Epoch 903/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 466552704.0000 - val_loss: 1412455040.0000\n",
      "Epoch 904/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 466095296.0000 - val_loss: 1412597120.0000\n",
      "Epoch 905/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 465687360.0000 - val_loss: 1411908992.0000\n",
      "Epoch 906/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 465419808.0000 - val_loss: 1410614400.0000\n",
      "Epoch 907/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 464878592.0000 - val_loss: 1411845248.0000\n",
      "Epoch 908/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 464326432.0000 - val_loss: 1410683008.0000\n",
      "Epoch 909/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 463983136.0000 - val_loss: 1409800832.0000\n",
      "Epoch 910/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 463727424.0000 - val_loss: 1409513216.0000\n",
      "Epoch 911/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 463179904.0000 - val_loss: 1409278976.0000\n",
      "Epoch 912/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 462688992.0000 - val_loss: 1408132480.0000\n",
      "Epoch 913/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 462337536.0000 - val_loss: 1408099328.0000\n",
      "Epoch 914/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 461644416.0000 - val_loss: 1408419072.0000\n",
      "Epoch 915/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 461313600.0000 - val_loss: 1407975424.0000\n",
      "Epoch 916/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 461055584.0000 - val_loss: 1408057344.0000\n",
      "Epoch 917/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 460467264.0000 - val_loss: 1407703424.0000\n",
      "Epoch 918/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 459997440.0000 - val_loss: 1407782912.0000\n",
      "Epoch 919/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 459470976.0000 - val_loss: 1406877568.0000\n",
      "Epoch 920/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 459011744.0000 - val_loss: 1406245504.0000\n",
      "Epoch 921/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 458596288.0000 - val_loss: 1404791808.0000\n",
      "Epoch 922/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 458564800.0000 - val_loss: 1404984448.0000\n",
      "Epoch 923/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 457906496.0000 - val_loss: 1405156480.0000\n",
      "Epoch 924/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 457263360.0000 - val_loss: 1403573632.0000\n",
      "Epoch 925/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 456915616.0000 - val_loss: 1403877248.0000\n",
      "Epoch 926/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 456618816.0000 - val_loss: 1403011584.0000\n",
      "Epoch 927/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 456032320.0000 - val_loss: 1402912384.0000\n",
      "Epoch 928/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 455728832.0000 - val_loss: 1403111680.0000\n",
      "Epoch 929/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 455179456.0000 - val_loss: 1401553536.0000\n",
      "Epoch 930/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 454758080.0000 - val_loss: 1401528576.0000\n",
      "Epoch 931/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 454299264.0000 - val_loss: 1401394048.0000\n",
      "Epoch 932/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 453905408.0000 - val_loss: 1400968704.0000\n",
      "Epoch 933/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 453487072.0000 - val_loss: 1400424064.0000\n",
      "Epoch 934/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 453636384.0000 - val_loss: 1401723392.0000\n",
      "Epoch 935/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 452561696.0000 - val_loss: 1398960128.0000\n",
      "Epoch 936/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 452328768.0000 - val_loss: 1397763968.0000\n",
      "Epoch 937/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 451899072.0000 - val_loss: 1399976576.0000\n",
      "Epoch 938/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 451242080.0000 - val_loss: 1398694400.0000\n",
      "Epoch 939/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 451119168.0000 - val_loss: 1398633728.0000\n",
      "Epoch 940/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 450465664.0000 - val_loss: 1398257536.0000\n",
      "Epoch 941/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 450326016.0000 - val_loss: 1396339840.0000\n",
      "Epoch 942/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 449697344.0000 - val_loss: 1396463744.0000\n",
      "Epoch 943/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 449447328.0000 - val_loss: 1396617600.0000\n",
      "Epoch 944/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 448912640.0000 - val_loss: 1395673088.0000\n",
      "Epoch 945/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 448743232.0000 - val_loss: 1396248832.0000\n",
      "Epoch 946/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 448214368.0000 - val_loss: 1395913472.0000\n",
      "Epoch 947/1000\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 447647872.0000 - val_loss: 1394537472.0000\n",
      "Epoch 948/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 447342240.0000 - val_loss: 1394246528.0000\n",
      "Epoch 949/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 447408000.0000 - val_loss: 1392636928.0000\n",
      "Epoch 950/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 446588256.0000 - val_loss: 1394241664.0000\n",
      "Epoch 951/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 446066912.0000 - val_loss: 1394467712.0000\n",
      "Epoch 952/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 445779136.0000 - val_loss: 1393644544.0000\n",
      "Epoch 953/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 445204480.0000 - val_loss: 1391819776.0000\n",
      "Epoch 954/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 445048960.0000 - val_loss: 1393339008.0000\n",
      "Epoch 955/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 444618816.0000 - val_loss: 1391688960.0000\n",
      "Epoch 956/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 444133184.0000 - val_loss: 1392165376.0000\n",
      "Epoch 957/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 443729440.0000 - val_loss: 1390625536.0000\n",
      "Epoch 958/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 443516960.0000 - val_loss: 1390792320.0000\n",
      "Epoch 959/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 442775840.0000 - val_loss: 1390776192.0000\n",
      "Epoch 960/1000\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 442535584.0000 - val_loss: 1390768256.0000\n",
      "Epoch 961/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 442086432.0000 - val_loss: 1389732608.0000\n",
      "Epoch 962/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 441957056.0000 - val_loss: 1390067456.0000\n",
      "Epoch 963/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 441606496.0000 - val_loss: 1388405760.0000\n",
      "Epoch 964/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 441167456.0000 - val_loss: 1389679744.0000\n",
      "Epoch 965/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 440607680.0000 - val_loss: 1389222528.0000\n",
      "Epoch 966/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 440123168.0000 - val_loss: 1388186112.0000\n",
      "Epoch 967/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 440036800.0000 - val_loss: 1386622208.0000\n",
      "Epoch 968/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 439404352.0000 - val_loss: 1387396992.0000\n",
      "Epoch 969/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 439082432.0000 - val_loss: 1386139904.0000\n",
      "Epoch 970/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 439540096.0000 - val_loss: 1388954496.0000\n",
      "Epoch 971/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 438069440.0000 - val_loss: 1386314368.0000\n",
      "Epoch 972/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 437820064.0000 - val_loss: 1384613248.0000\n",
      "Epoch 973/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 437469952.0000 - val_loss: 1385268864.0000\n",
      "Epoch 974/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 437059936.0000 - val_loss: 1385653888.0000\n",
      "Epoch 975/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 436649184.0000 - val_loss: 1384807936.0000\n",
      "Epoch 976/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 436571936.0000 - val_loss: 1385001856.0000\n",
      "Epoch 977/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 436431872.0000 - val_loss: 1384146176.0000\n",
      "Epoch 978/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 436064256.0000 - val_loss: 1384515328.0000\n",
      "Epoch 979/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 435134112.0000 - val_loss: 1382593024.0000\n",
      "Epoch 980/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 434935328.0000 - val_loss: 1382277632.0000\n",
      "Epoch 981/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 434737184.0000 - val_loss: 1382096896.0000\n",
      "Epoch 982/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 434481312.0000 - val_loss: 1381829888.0000\n",
      "Epoch 983/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 433900320.0000 - val_loss: 1381053312.0000\n",
      "Epoch 984/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 433373184.0000 - val_loss: 1381455104.0000\n",
      "Epoch 985/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 432956416.0000 - val_loss: 1380520064.0000\n",
      "Epoch 986/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 432687392.0000 - val_loss: 1379837952.0000\n",
      "Epoch 987/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 432158944.0000 - val_loss: 1379788288.0000\n",
      "Epoch 988/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 431968032.0000 - val_loss: 1379632512.0000\n",
      "Epoch 989/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 431515744.0000 - val_loss: 1379986688.0000\n",
      "Epoch 990/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 431122208.0000 - val_loss: 1378758528.0000\n",
      "Epoch 991/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 430764192.0000 - val_loss: 1378511104.0000\n",
      "Epoch 992/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 430367584.0000 - val_loss: 1377982208.0000\n",
      "Epoch 993/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 429896096.0000 - val_loss: 1378714624.0000\n",
      "Epoch 994/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 430246752.0000 - val_loss: 1377971712.0000\n",
      "Epoch 995/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 429284160.0000 - val_loss: 1376983552.0000\n",
      "Epoch 996/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 428937440.0000 - val_loss: 1376454784.0000\n",
      "Epoch 997/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 428684032.0000 - val_loss: 1374764800.0000\n",
      "Epoch 998/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 428579712.0000 - val_loss: 1376150784.0000\n",
      "Epoch 999/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 427853472.0000 - val_loss: 1374912256.0000\n",
      "Epoch 1000/1000\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 427597952.0000 - val_loss: 1373854464.0000\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#train the model, graph the loss\n",
    "history = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=1000, verbose=1)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(history.history['val_loss'], label='val_loss')\n",
    "plt.plot(history.history['loss'], label='loss')\n",
    "#add ticks every 25 epochs\n",
    "plt.xticks(range(0, 1000, 25))\n",
    "plt.legend()\n",
    "plt.show()\n",
    "# about 275 epochs is plenty"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
