{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-26 23:53:43.234721: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-03-26 23:53:43.256934: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-03-26 23:53:43.256954: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-03-26 23:53:43.257513: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-03-26 23:53:43.261346: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "\n",
    "from scripts.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-26 23:53:44.221237: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-26 23:53:44.224444: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-26 23:53:44.224477: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n"
     ]
    }
   ],
   "source": [
    "#use gpu for tf\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "train_data = pd.read_csv('../data/train.csv')\n",
    "test_data = pd.read_csv('../data/test.csv')\n",
    "\n",
    "# split train data into predictors and response\n",
    "X = train_data.drop(columns=['SalePrice'])\n",
    "y = train_data['SalePrice'] \n",
    "\n",
    "#combine the data for preprocessing\n",
    "data = pd.concat([X, test_data], axis=0)\n",
    "# Preprocess the data\n",
    "data = Pipeline(data)\n",
    "\n",
    "# Split the data back into train and test, processed\n",
    "X = data[:len(train_data)]\n",
    "test = data[len(train_data):]\n",
    "#increase test index by 1\n",
    "test.index += 1\n",
    "\n",
    "# Split the data into features and response\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#going with extra trees regressor\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "model = ExtraTreesRegressor()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict the test data\n",
    "y_pred = model.predict(test)\n",
    "test_results = pd.DataFrame({'Id': test.index, 'SalePrice': y_pred})\n",
    "test_results.to_csv('../outputs/ExtraTreesRegressor_test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#going with gradient boosting regressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "model = GradientBoostingRegressor()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict the test data\n",
    "y_pred = model.predict(test)\n",
    "test_results = pd.DataFrame({'Id': test.index, 'SalePrice': y_pred})\n",
    "test_results.to_csv('../outputs/GradientBoostingRegressor_test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-26 23:53:46.428336: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-26 23:53:46.428383: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-26 23:53:46.428405: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-26 23:53:46.520821: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-26 23:53:46.520866: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-26 23:53:46.520872: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2022] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2024-03-26 23:53:46.520899: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-03-26 23:53:46.520910: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21784 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "# build nn model\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Dense(128, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-26 23:53:47.173341: I external/local_xla/xla/service/service.cc:168] XLA service 0x7ff87d93ab20 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-03-26 23:53:47.173363: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 3090, Compute Capability 8.6\n",
      "2024-03-26 23:53:47.177965: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-03-26 23:53:47.191698: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8906\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1711497227.232594   24071 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37/37 [==============================] - 1s 3ms/step - loss: 38885658624.0000\n",
      "Epoch 2/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 38885392384.0000\n",
      "Epoch 3/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 38885052416.0000\n",
      "Epoch 4/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 38884474880.0000\n",
      "Epoch 5/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 38883622912.0000\n",
      "Epoch 6/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 38882422784.0000\n",
      "Epoch 7/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 38880727040.0000\n",
      "Epoch 8/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 38878498816.0000\n",
      "Epoch 9/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 38875561984.0000\n",
      "Epoch 10/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 38871777280.0000\n",
      "Epoch 11/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 38867116032.0000\n",
      "Epoch 12/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 38861373440.0000\n",
      "Epoch 13/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 38854606848.0000\n",
      "Epoch 14/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 38846656512.0000\n",
      "Epoch 15/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 38837526528.0000\n",
      "Epoch 16/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 38827044864.0000\n",
      "Epoch 17/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 38815117312.0000\n",
      "Epoch 18/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 38801534976.0000\n",
      "Epoch 19/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 38786248704.0000\n",
      "Epoch 20/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 38769197056.0000\n",
      "Epoch 21/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 38750429184.0000\n",
      "Epoch 22/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 38728544256.0000\n",
      "Epoch 23/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 38702325760.0000\n",
      "Epoch 24/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 38670925824.0000\n",
      "Epoch 25/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 38635233280.0000\n",
      "Epoch 26/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 38595522560.0000\n",
      "Epoch 27/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 38551830528.0000\n",
      "Epoch 28/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 38504108032.0000\n",
      "Epoch 29/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 38452346880.0000\n",
      "Epoch 30/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 38396153856.0000\n",
      "Epoch 31/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 38335926272.0000\n",
      "Epoch 32/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 38271168512.0000\n",
      "Epoch 33/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 38202318848.0000\n",
      "Epoch 34/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 38128652288.0000\n",
      "Epoch 35/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 38050705408.0000\n",
      "Epoch 36/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 37968297984.0000\n",
      "Epoch 37/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 37881434112.0000\n",
      "Epoch 38/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 37790121984.0000\n",
      "Epoch 39/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 37694304256.0000\n",
      "Epoch 40/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 37593923584.0000\n",
      "Epoch 41/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 37489221632.0000\n",
      "Epoch 42/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 37380390912.0000\n",
      "Epoch 43/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 37266628608.0000\n",
      "Epoch 44/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 37148418048.0000\n",
      "Epoch 45/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 37026074624.0000\n",
      "Epoch 46/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 36898529280.0000\n",
      "Epoch 47/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 36766248960.0000\n",
      "Epoch 48/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 36630335488.0000\n",
      "Epoch 49/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 36489302016.0000\n",
      "Epoch 50/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 36345315328.0000\n",
      "Epoch 51/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 36195581952.0000\n",
      "Epoch 52/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 36042162176.0000\n",
      "Epoch 53/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 35884494848.0000\n",
      "Epoch 54/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 35721719808.0000\n",
      "Epoch 55/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 35555508224.0000\n",
      "Epoch 56/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 35384434688.0000\n",
      "Epoch 57/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 35209650176.0000\n",
      "Epoch 58/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 35030585344.0000\n",
      "Epoch 59/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 34847371264.0000\n",
      "Epoch 60/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 34660024320.0000\n",
      "Epoch 61/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 34469187584.0000\n",
      "Epoch 62/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 34274365440.0000\n",
      "Epoch 63/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 34075131904.0000\n",
      "Epoch 64/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 33872959488.0000\n",
      "Epoch 65/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 33667092480.0000\n",
      "Epoch 66/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 33457399808.0000\n",
      "Epoch 67/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 33245212672.0000\n",
      "Epoch 68/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 33028331520.0000\n",
      "Epoch 69/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 32809170944.0000\n",
      "Epoch 70/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 32587186176.0000\n",
      "Epoch 71/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 32360243200.0000\n",
      "Epoch 72/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 32131594240.0000\n",
      "Epoch 73/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 31898525696.0000\n",
      "Epoch 74/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 31663120384.0000\n",
      "Epoch 75/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 31425859584.0000\n",
      "Epoch 76/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 31186161664.0000\n",
      "Epoch 77/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 30941372416.0000\n",
      "Epoch 78/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 30695532544.0000\n",
      "Epoch 79/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 30447443968.0000\n",
      "Epoch 80/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 30195499008.0000\n",
      "Epoch 81/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 29942677504.0000\n",
      "Epoch 82/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 29688864768.0000\n",
      "Epoch 83/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 29430380544.0000\n",
      "Epoch 84/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 29173071872.0000\n",
      "Epoch 85/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 28911161344.0000\n",
      "Epoch 86/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 28649359360.0000\n",
      "Epoch 87/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 28387530752.0000\n",
      "Epoch 88/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 28121153536.0000\n",
      "Epoch 89/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 27855677440.0000\n",
      "Epoch 90/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 27587395584.0000\n",
      "Epoch 91/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 27318503424.0000\n",
      "Epoch 92/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 27047047168.0000\n",
      "Epoch 93/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 26775486464.0000\n",
      "Epoch 94/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 26503176192.0000\n",
      "Epoch 95/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 26230063104.0000\n",
      "Epoch 96/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 25955033088.0000\n",
      "Epoch 97/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 25680398336.0000\n",
      "Epoch 98/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 25404573696.0000\n",
      "Epoch 99/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 25128583168.0000\n",
      "Epoch 100/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 24852586496.0000\n",
      "Epoch 101/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 24575424512.0000\n",
      "Epoch 102/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 24297295872.0000\n",
      "Epoch 103/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 24018577408.0000\n",
      "Epoch 104/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 23740682240.0000\n",
      "Epoch 105/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 23463176192.0000\n",
      "Epoch 106/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 23186821120.0000\n",
      "Epoch 107/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 22911309824.0000\n",
      "Epoch 108/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 22637182976.0000\n",
      "Epoch 109/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 22360934400.0000\n",
      "Epoch 110/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 22084737024.0000\n",
      "Epoch 111/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 21810120704.0000\n",
      "Epoch 112/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 21536051200.0000\n",
      "Epoch 113/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 21263585280.0000\n",
      "Epoch 114/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 20992784384.0000\n",
      "Epoch 115/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 20720752640.0000\n",
      "Epoch 116/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 20451610624.0000\n",
      "Epoch 117/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 20181016576.0000\n",
      "Epoch 118/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 19912943616.0000\n",
      "Epoch 119/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 19646214144.0000\n",
      "Epoch 120/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 19378798592.0000\n",
      "Epoch 121/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 19116122112.0000\n",
      "Epoch 122/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 18852112384.0000\n",
      "Epoch 123/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 18591875072.0000\n",
      "Epoch 124/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 18331396096.0000\n",
      "Epoch 125/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 18072156160.0000\n",
      "Epoch 126/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 17815336960.0000\n",
      "Epoch 127/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 17560811520.0000\n",
      "Epoch 128/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 17308954624.0000\n",
      "Epoch 129/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 17056923648.0000\n",
      "Epoch 130/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 16810439680.0000\n",
      "Epoch 131/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 16561767424.0000\n",
      "Epoch 132/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 16318189568.0000\n",
      "Epoch 133/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 16074217472.0000\n",
      "Epoch 134/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 15833643008.0000\n",
      "Epoch 135/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 15594141696.0000\n",
      "Epoch 136/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 15359498240.0000\n",
      "Epoch 137/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 15124489216.0000\n",
      "Epoch 138/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 14892583936.0000\n",
      "Epoch 139/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 14663844864.0000\n",
      "Epoch 140/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 14435897344.0000\n",
      "Epoch 141/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 14210378752.0000\n",
      "Epoch 142/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 13990508544.0000\n",
      "Epoch 143/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 13767059456.0000\n",
      "Epoch 144/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 13550457856.0000\n",
      "Epoch 145/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 13332142080.0000\n",
      "Epoch 146/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 13119312896.0000\n",
      "Epoch 147/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 12906714112.0000\n",
      "Epoch 148/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 12696957952.0000\n",
      "Epoch 149/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 12487898112.0000\n",
      "Epoch 150/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 12283196416.0000\n",
      "Epoch 151/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 12081043456.0000\n",
      "Epoch 152/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 11882149888.0000\n",
      "Epoch 153/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 11684476928.0000\n",
      "Epoch 154/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 11489434624.0000\n",
      "Epoch 155/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 11298265088.0000\n",
      "Epoch 156/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 11107632128.0000\n",
      "Epoch 157/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 10921207808.0000\n",
      "Epoch 158/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 10734712832.0000\n",
      "Epoch 159/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 10553222144.0000\n",
      "Epoch 160/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 10369253376.0000\n",
      "Epoch 161/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 10192416768.0000\n",
      "Epoch 162/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 10015330304.0000\n",
      "Epoch 163/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 9841925120.0000\n",
      "Epoch 164/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 9670983680.0000\n",
      "Epoch 165/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 9501383680.0000\n",
      "Epoch 166/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 9332976640.0000\n",
      "Epoch 167/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 9169499136.0000\n",
      "Epoch 168/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 9006372864.0000\n",
      "Epoch 169/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 8844391424.0000\n",
      "Epoch 170/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 8686953472.0000\n",
      "Epoch 171/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 8529858048.0000\n",
      "Epoch 172/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 8375767552.0000\n",
      "Epoch 173/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 8223123456.0000\n",
      "Epoch 174/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 8071455232.0000\n",
      "Epoch 175/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 7922776064.0000\n",
      "Epoch 176/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 7774105600.0000\n",
      "Epoch 177/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 7631413248.0000\n",
      "Epoch 178/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 7487236096.0000\n",
      "Epoch 179/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 7345383424.0000\n",
      "Epoch 180/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 7205941248.0000\n",
      "Epoch 181/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 7069331456.0000\n",
      "Epoch 182/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 6935145984.0000\n",
      "Epoch 183/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 6803857408.0000\n",
      "Epoch 184/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 6672151040.0000\n",
      "Epoch 185/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 6545271296.0000\n",
      "Epoch 186/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 6417621504.0000\n",
      "Epoch 187/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 6294592000.0000\n",
      "Epoch 188/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 6173358592.0000\n",
      "Epoch 189/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 6052452352.0000\n",
      "Epoch 190/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 5934647808.0000\n",
      "Epoch 191/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 5818469888.0000\n",
      "Epoch 192/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 5704972288.0000\n",
      "Epoch 193/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 5591789056.0000\n",
      "Epoch 194/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 5482593280.0000\n",
      "Epoch 195/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 5375069184.0000\n",
      "Epoch 196/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 5269940736.0000\n",
      "Epoch 197/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 5166441472.0000\n",
      "Epoch 198/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 5063125504.0000\n",
      "Epoch 199/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 4966034432.0000\n",
      "Epoch 200/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 4868601856.0000\n",
      "Epoch 201/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 4772793856.0000\n",
      "Epoch 202/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 4680008192.0000\n",
      "Epoch 203/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 4588738560.0000\n",
      "Epoch 204/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 4499488768.0000\n",
      "Epoch 205/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 4412926464.0000\n",
      "Epoch 206/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 4326608896.0000\n",
      "Epoch 207/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 4244214272.0000\n",
      "Epoch 208/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 4163248384.0000\n",
      "Epoch 209/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 4083788288.0000\n",
      "Epoch 210/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 4006204416.0000\n",
      "Epoch 211/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 3931576064.0000\n",
      "Epoch 212/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 3857634816.0000\n",
      "Epoch 213/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 3788189184.0000\n",
      "Epoch 214/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 3719398400.0000\n",
      "Epoch 215/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 3651985152.0000\n",
      "Epoch 216/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 3587419904.0000\n",
      "Epoch 217/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 3524059136.0000\n",
      "Epoch 218/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 3463809792.0000\n",
      "Epoch 219/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 3404055040.0000\n",
      "Epoch 220/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 3346795520.0000\n",
      "Epoch 221/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 3291983616.0000\n",
      "Epoch 222/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 3236466688.0000\n",
      "Epoch 223/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 3185847808.0000\n",
      "Epoch 224/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 3134786304.0000\n",
      "Epoch 225/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 3086697728.0000\n",
      "Epoch 226/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 3039830016.0000\n",
      "Epoch 227/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 2995112704.0000\n",
      "Epoch 228/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 2950640640.0000\n",
      "Epoch 229/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 2908878336.0000\n",
      "Epoch 230/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 2868991232.0000\n",
      "Epoch 231/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 2829707776.0000\n",
      "Epoch 232/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 2793002752.0000\n",
      "Epoch 233/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 2757124864.0000\n",
      "Epoch 234/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 2722392576.0000\n",
      "Epoch 235/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 2689888768.0000\n",
      "Epoch 236/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 2658253056.0000\n",
      "Epoch 237/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 2627878912.0000\n",
      "Epoch 238/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 2598251008.0000\n",
      "Epoch 239/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 2570696704.0000\n",
      "Epoch 240/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 2544554496.0000\n",
      "Epoch 241/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 2518582784.0000\n",
      "Epoch 242/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 2493300736.0000\n",
      "Epoch 243/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 2470155264.0000\n",
      "Epoch 244/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 2447368448.0000\n",
      "Epoch 245/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 2425441280.0000\n",
      "Epoch 246/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 2405265664.0000\n",
      "Epoch 247/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 2385414912.0000\n",
      "Epoch 248/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 2366251264.0000\n",
      "Epoch 249/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 2348402944.0000\n",
      "Epoch 250/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 2331129856.0000\n",
      "Epoch 251/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 2314450176.0000\n",
      "Epoch 252/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 2298156032.0000\n",
      "Epoch 253/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 2282718208.0000\n",
      "Epoch 254/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 2268464384.0000\n",
      "Epoch 255/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 2253909504.0000\n",
      "Epoch 256/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 2240840704.0000\n",
      "Epoch 257/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 2227459840.0000\n",
      "Epoch 258/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 2214992128.0000\n",
      "Epoch 259/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 2202871552.0000\n",
      "Epoch 260/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 2191074048.0000\n",
      "Epoch 261/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 2180329216.0000\n",
      "Epoch 262/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 2169197056.0000\n",
      "Epoch 263/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 2158744064.0000\n",
      "Epoch 264/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 2148856320.0000\n",
      "Epoch 265/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 2138854400.0000\n",
      "Epoch 266/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 2129874048.0000\n",
      "Epoch 267/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 2120034816.0000\n",
      "Epoch 268/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 2110969344.0000\n",
      "Epoch 269/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 2102383488.0000\n",
      "Epoch 270/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 2093717888.0000\n",
      "Epoch 271/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 2085246848.0000\n",
      "Epoch 272/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 2077395584.0000\n",
      "Epoch 273/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 2069087360.0000\n",
      "Epoch 274/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 2061449472.0000\n",
      "Epoch 275/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 2053443968.0000\n",
      "Epoch 276/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 2046206080.0000\n",
      "Epoch 277/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 2038717056.0000\n",
      "Epoch 278/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 2031642496.0000\n",
      "Epoch 279/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 2024188416.0000\n",
      "Epoch 280/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 2017206400.0000\n",
      "Epoch 281/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 2010327552.0000\n",
      "Epoch 282/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 2003571072.0000\n",
      "Epoch 283/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 1996790784.0000\n",
      "Epoch 284/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 1989689600.0000\n",
      "Epoch 285/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 1982825856.0000\n",
      "Epoch 286/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 1976348672.0000\n",
      "Epoch 287/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 1969918848.0000\n",
      "Epoch 288/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 1963451136.0000\n",
      "Epoch 289/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 1957079168.0000\n",
      "Epoch 290/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 1950749952.0000\n",
      "Epoch 291/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 1944403456.0000\n",
      "Epoch 292/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 1938277248.0000\n",
      "Epoch 293/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 1932051840.0000\n",
      "Epoch 294/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 1925725696.0000\n",
      "Epoch 295/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 1919661440.0000\n",
      "Epoch 296/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 1913602688.0000\n",
      "Epoch 297/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 1907593600.0000\n",
      "Epoch 298/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 1901438208.0000\n",
      "Epoch 299/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 1895834880.0000\n",
      "Epoch 300/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 1889553920.0000\n",
      "Epoch 301/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 1883526144.0000\n",
      "Epoch 302/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 1877957632.0000\n",
      "Epoch 303/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 1872014848.0000\n",
      "Epoch 304/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 1866339840.0000\n",
      "Epoch 305/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 1860332032.0000\n",
      "Epoch 306/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 1854691840.0000\n",
      "Epoch 307/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 1849113856.0000\n",
      "Epoch 308/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 1843210496.0000\n",
      "Epoch 309/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 1837508224.0000\n",
      "Epoch 310/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 1832271104.0000\n",
      "Epoch 311/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 1826640640.0000\n",
      "Epoch 312/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 1820688256.0000\n",
      "Epoch 313/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 1815371648.0000\n",
      "Epoch 314/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 1809779840.0000\n",
      "Epoch 315/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 1804330752.0000\n",
      "Epoch 316/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 1798734848.0000\n",
      "Epoch 317/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 1793364608.0000\n",
      "Epoch 318/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 1787847040.0000\n",
      "Epoch 319/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 1782547456.0000\n",
      "Epoch 320/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 1777219072.0000\n",
      "Epoch 321/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 1771765376.0000\n",
      "Epoch 322/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 1766259328.0000\n",
      "Epoch 323/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 1761181184.0000\n",
      "Epoch 324/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 1755683456.0000\n",
      "Epoch 325/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 1750120192.0000\n",
      "Epoch 326/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 1744752896.0000\n",
      "Epoch 327/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 1739442944.0000\n",
      "Epoch 328/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 1734073088.0000\n",
      "Epoch 329/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 1728679680.0000\n",
      "Epoch 330/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 1723569792.0000\n",
      "Epoch 331/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 1718262144.0000\n",
      "Epoch 332/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 1713178880.0000\n",
      "Epoch 333/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 1708266880.0000\n",
      "Epoch 334/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 1703009280.0000\n",
      "Epoch 335/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 1697914368.0000\n",
      "Epoch 336/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 1692289280.0000\n",
      "Epoch 337/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 1687255808.0000\n",
      "Epoch 338/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 1682170240.0000\n",
      "Epoch 339/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 1677622656.0000\n",
      "Epoch 340/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 1671926656.0000\n",
      "Epoch 341/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 1667241344.0000\n",
      "Epoch 342/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 1661848576.0000\n",
      "Epoch 343/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 1656997248.0000\n",
      "Epoch 344/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 1652198656.0000\n",
      "Epoch 345/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 1647097856.0000\n",
      "Epoch 346/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 1642551424.0000\n",
      "Epoch 347/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 1637350272.0000\n",
      "Epoch 348/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 1633161216.0000\n",
      "Epoch 349/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 1627537280.0000\n",
      "Epoch 350/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 1623198720.0000\n",
      "Epoch 351/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 1618163584.0000\n",
      "Epoch 352/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 1613677056.0000\n",
      "Epoch 353/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 1608605184.0000\n",
      "Epoch 354/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 1604140416.0000\n",
      "Epoch 355/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 1599418752.0000\n",
      "Epoch 356/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 1595255424.0000\n",
      "Epoch 357/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 1590379776.0000\n",
      "Epoch 358/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 1585806080.0000\n",
      "Epoch 359/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 1580872448.0000\n",
      "Epoch 360/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 1576572288.0000\n",
      "Epoch 361/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 1571943296.0000\n",
      "Epoch 362/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 1567445632.0000\n",
      "Epoch 363/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 1563169664.0000\n",
      "Epoch 364/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 1558445824.0000\n",
      "Epoch 365/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 1554279168.0000\n",
      "Epoch 366/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 1549688448.0000\n",
      "Epoch 367/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 1545223552.0000\n",
      "Epoch 368/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 1541097472.0000\n",
      "Epoch 369/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 1536638464.0000\n",
      "Epoch 370/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 1532816256.0000\n",
      "Epoch 371/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 1527933568.0000\n",
      "Epoch 372/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 1523991040.0000\n",
      "Epoch 373/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 1519586432.0000\n",
      "Epoch 374/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 1515228288.0000\n",
      "Epoch 375/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 1511026432.0000\n",
      "Epoch 376/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 1507118464.0000\n",
      "Epoch 377/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 1502892928.0000\n",
      "Epoch 378/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 1498563968.0000\n",
      "Epoch 379/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 1494403584.0000\n",
      "Epoch 380/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 1490876160.0000\n",
      "Epoch 381/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 1485952384.0000\n",
      "Epoch 382/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 1482467456.0000\n",
      "Epoch 383/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 1478132480.0000\n",
      "Epoch 384/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 1473822720.0000\n",
      "Epoch 385/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 1469708800.0000\n",
      "Epoch 386/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 1465631360.0000\n",
      "Epoch 387/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 1461528832.0000\n",
      "Epoch 388/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 1458239616.0000\n",
      "Epoch 389/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 1453370496.0000\n",
      "Epoch 390/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 1449938304.0000\n",
      "Epoch 391/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 1445727232.0000\n",
      "Epoch 392/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 1441613312.0000\n",
      "Epoch 393/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 1437752192.0000\n",
      "Epoch 394/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 1433846912.0000\n",
      "Epoch 395/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 1430014208.0000\n",
      "Epoch 396/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 1425988352.0000\n",
      "Epoch 397/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 1422356608.0000\n",
      "Epoch 398/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 1418458240.0000\n",
      "Epoch 399/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 1414389888.0000\n",
      "Epoch 400/400\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 1411032704.0000\n",
      "46/46 [==============================] - 0s 768us/step\n"
     ]
    }
   ],
   "source": [
    "# Train the model, predict the test data\n",
    "model.fit(X_train, y_train, epochs=250)\n",
    "y_pred = model.predict(test).flatten()\n",
    "test_results = pd.DataFrame({'Id': test.index, 'SalePrice': y_pred})\n",
    "test_results.to_csv('../outputs/NN128x128_test.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
